. cap cd "/Users/kahrens/MyProjects/pystacked/cert"

  ___  ____  ____  ____  ____ ®
 /__    /   ____/   /   ____/      17.0
___/   /   /___/   /   /___/       SE—Standard Edition

 Statistics and Data Science       Copyright 1985-2021 StataCorp LLC
                                   StataCorp
                                   4905 Lakeway Drive
                                   College Station, Texas 77845 USA
                                   800-STATA-PC        https://www.stata.com
                                   979-696-4600        stata@stata.com

Stata license: 100-user network perpetual
Serial number: 401706318278
  Licensed to: Staff
               ETH Zurich


. 
. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
. cap cd "/Users/kahrens/MyProjects/pystacked/cert"

. if "`c(username)'"=="kahrens" {
. if "`c(username)'"=="kahrens" {
. if "`c(username)'"=="kahrens" {
. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
.         adopath + "/Users/kahrens/MyProjects/pystacked"
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [1]  (BASE)      "/Applications/Stata 17/ado/base/"
  [2]  (SITE)      "/Applications/Stata 17/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }

  [1]  (BASE)      "/Applications/Stata 17/ado/base/"
  [2]  (SITE)      "/Applications/Stata 17/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [1]  (BASE)      "/Applications/Stata 17/ado/base/"
 Support/Stata/ado/plus/"
  [2]  (SITE)      "/Applications/Stata 17/ado/site/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }
]              "."

  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }


Notes:
      1. Stata is running in batch mode.
      2. Unicode is supported; see help unicode_advice.
      3. Maximum number of variables is set to 5,000; see help set_maxvar.

. do cs_pystacked_runall.do 112 

. if "`c(username)'"=="kahrens" {
. clear all
. else if "`c(username)'"=="ecomes" {
. else if "`c(username)'"=="ecomes" {
. else if "`c(username)'"=="ecomes" {
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [1]  (BASE)      "/Applications/Stata 17/ado/base/"
  [2]  (SITE)      "/Applications/Stata 17/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }

.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
. else {
. else if "`c(username)'"=="ecomes" {

. 
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
. cap cd "/Users/kahrens/MyProjects/pystacked/cert"

.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
. local ver `0'

. 
. local ver `0'

. 
. local ver `0'

. 
. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
. if "`c(username)'"=="kahrens" {
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
. cap python set exec "/Users/kahrens/python_envs/sk`ver'/bin/python3"
. cap python set exec "/Users/kahrens/python_envs/sk`ver'/bin/python3"
. local ver `0'

. 
. cap python set exec "/Users/kahrens/python_envs/sk`ver'/bin/python3"
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [1]  (BASE)      "/Applications/Stata 17/ado/base/"
  [2]  (SITE)      "/Applications/Stata 17/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }

. cap python set exec "/Users/kahrens/python_envs/sk`ver'/bin/python3"
. else if "`c(username)'"=="ecomes" {
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
. local ver `0'

. 
. cap python set exec "/Users/kahrens/python_envs/sk`ver'/bin/python3"

. 
. 
. 
. cap log close

. cap log close

. cap log close

. cap log close


. 
. log using "log_cs_pystacked_`ver'.txt", text replace
. log using "log_cs_pystacked_`ver'.txt", text replace
. log using "log_cs_pystacked_`ver'.txt", text replace
. log using "log_cs_pystacked_`ver'.txt", text replace
. cap log close

---------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_024.txt
  log type:  text
 opened on:  18 Aug 2022, 23:11:00

. 
. do "cs_pystacked_class.do"
. log using "log_cs_pystacked_`ver'.txt", text replace

. 
. 
. which pystacked 
---------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_100.txt
  log type:  text
 opened on:  18 Aug 2022, 23:11:00

. 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn
. do "cs_pystacked_class.do"

. 
. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn
---------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_112.txt
  log type:  text
 opened on:  18 Aug 2022, 23:11:00

---------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_110.txt
  log type:  text
 opened on:  18 Aug 2022, 23:11:00

. 
. 
. 
. do "cs_pystacked_class.do"
. do "cs_pystacked_class.do"

. 
. 
. which pystacked 
. do "cs_pystacked_class.do"

. 
. 
. which pystacked 

. 
. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.0'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, c
> lear comma

. python: sklearn.__version__
'1.1.1'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, c
> lear comma

. python: sklearn.__version__
'0.24.0'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, c
> lear comma

. python: sklearn.__version__
'1.1.0'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, c
> lear comma

. python: sklearn.__version__
'1.1.2'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, c
> lear comma
(58 vars, 4,601 obs)

. sample 15
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75

. save `testdata'
file /var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//S_57600.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear

. 
. pystacked $model, type(class) pyseed(123)
(58 vars, 4,601 obs)

. sample 15
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75

. save `testdata'
file /var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//S_57597.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear

. 
. pystacked $model, type(class) pyseed(123)
(58 vars, 4,601 obs)

. sample 15
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75


. save `testdata'
. sample 15
file /var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//S_57598.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear
(58 vars, 4,601 obs)

. sample 15
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75

. save `testdata'
file /var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//S_57596.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75

. save `testdata'
file /var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//S_57599.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear

. 
. pystacked $model, type(class) pyseed(123)

. 
. pystacked $model, type(class) pyseed(123)

. 
. pystacked $model, type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545443
  lassocv        |      0.0000000
  gradboost      |      0.8454557

. 
. predict double yhat, pr

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02155075 |
  2. |  .0130224 |
  3. | .00746404 |
  4. | .96343335 |
  5. | .98904361 |
     |-----------|
  6. | .01330954 |
  7. |  .1035354 |
  8. | .98451701 |
  9. | .07357371 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. 
. *******************************************************************************
. *** predicted values/classes                                                                     
>                        ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545403
  lassocv        |      0.0000000
  gradboost      |      0.8454597

. 
. predict double yhat, pr

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02155076 |
  2. | .01302247 |
  3. | .00746408 |
  4. | .96343312 |
  5. | .98904331 |
     |-----------|
  6. | .01330911 |
  7. | .10353401 |
  8. | .98451638 |
  9. | .07357842 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. 
. *******************************************************************************
. *** predicted values/classes                                                                     
>                        ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                   
>                                        ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                   
>                                        ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545403
  lassocv        |      0.0000000
  gradboost      |      0.8454597

. 
. predict double yhat, pr

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02155076 |
  2. | .01302247 |
  3. | .00746408 |
  4. | .96343312 |
  5. | .98904331 |
     |-----------|
  6. | .01330911 |
  7. | .10353401 |
  8. | .98451638 |
  9. | .07357842 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. 
. *******************************************************************************
. *** predicted values/classes                                                                     
>                        ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545443
  lassocv        |      0.0000000
  gradboost      |      0.8454557

. 
. predict double yhat, pr

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02155075 |
  2. |  .0130224 |
  3. | .00746404 |
  4. | .96343335 |
  5. | .98904361 |
     |-----------|
  6. | .01330954 |
  7. |  .1035354 |
  8. | .98451701 |
  9. | .07357371 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. 
. *******************************************************************************
. *** predicted values/classes                                                                     
>                        ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1538295
  lassocv        |      0.0000000
  gradboost      |      0.8461705

. 
. predict double yhat, pr
Single base learner: no stacking done.

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02156874 |
  2. | .01303298 |
  3. | .00747035 |
  4. | .96340283 |
  5. |  .9890357 |
     |-----------|
  6. | .01331666 |
  7. | .10338436 |
  8. | .98450776 |
  9. | .07355803 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. 
. *******************************************************************************
. *** predicted values/classes                                                                     
>                        ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                   
>                                        ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                   
>                                        ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                   
>                                        ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

.                         
. 
. *******************************************************************************
. *** try other estimators                                                                         
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

.                         
. 
. *******************************************************************************
. *** try other estimators                                                                         
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

.                         
. 
. *******************************************************************************
. *** try other estimators                                                                         
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

.                         
. 
. *******************************************************************************
. *** try other estimators                                                                         
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

.                         
. 
. *******************************************************************************
. *** try other estimators                                                                         
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      0.5639065
  nnet           |      0.4360935
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0052116
  lassocv        |      0.0000000
  rf             |      0.3801647
  nnet           |      0.6146237
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  rf             |      0.4985666
  nnet           |      0.5014334
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  lassocv        |      0.0000000
  rf             |      0.4985666
  nnet           |      0.5014334
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0052116
  lassocv        |      0.0000000
  rf             |      0.3801647
  nnet           |      0.6146237
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0052116
  lassocv        |      0.0000000
  rf             |      0.3801647
  nnet           |      0.6146237
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0000000
  gradboost      |      0.5639065
  nnet           |      0.4360935
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5639065
  nnet           |      0.4360935
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5623997
  nnet           |      0.4376003
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0659684
  elasticcv      |      0.0000000
  gradboost      |      0.6421295
  svm            |      0.2919021


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0659693
  elasticcv      |      0.0000000
  gradboost      |      0.6421272
  svm            |      0.2919036


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0659684
  elasticcv      |      0.0000000
  gradboost      |      0.6421295
  svm            |      0.2919021


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0655373
  elasticcv      |      0.0000000
  gradboost      |      0.6437763
  svm            |      0.2906864


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0659693
  elasticcv      |      0.0000000
  gradboost      |      0.6421272
  svm            |      0.2919036


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545425
  lassocv        |      0.0000000
  gradboost      |      0.8454575

. 
. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545385
  lassocv        |      0.0000000
  gradboost      |      0.8454615

. 
. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545425
  lassocv        |      0.0000000
  gradboost      |      0.8454575

. 
. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1538313
  lassocv        |      0.0000000
  gradboost      |      0.8461687

. 
. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1545385
  lassocv        |      0.0000000
  gradboost      |      0.8454615

. 
. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1178419
  rf             |      0.3414634
  gradboost      |      0.5406946

. pystacked, table

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       417      12         .       .
  STACKING     1 |    .         4     257         .       .
  logit        0 | 0.118      399      40         .       .
  logit        1 | 0.118       22     229         .       .
  rf           0 | 0.341      421       1         .       .
  rf           1 | 0.341        0     268         .       .
  gradboost    0 | 0.541      416      13         .       .
  gradboost    1 | 0.541        5     256         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1178419
  rf             |      0.3414634
  gradboost      |      0.5406946

. pystacked, table

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       417      12         .       .
  STACKING     1 |    .         4     257         .       .
  logit        0 | 0.118      399      40         .       .
  logit        1 | 0.118       22     229         .       .
  rf           0 | 0.341      421       1         .       .
  rf           1 | 0.341        0     268         .       .
  gradboost    0 | 0.541      416      13         .       .
  gradboost    1 | 0.541        5     256         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1597235
  rf             |      0.1829718
  gradboost      |      0.6573047

. pystacked, table

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       417      13         .       .
  STACKING     1 |    .         4     256         .       .
  logit        0 | 0.160      399      40         .       .
  logit        1 | 0.160       22     229         .       .
  rf           0 | 0.183      421       1         .       .
  rf           1 | 0.183        0     268         .       .
  gradboost    0 | 0.657      416      13         .       .
  gradboost    1 | 0.657        5     256         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4        98      10
  STACKING     1 |    .         0     118         3      64
  logit        0 | 0.331      196       7        93      11
  logit        1 | 0.331        7     115         8      63
  rf           0 | 0.457      203       1        97      13
  rf           1 | 0.457        0     121         4      61
  gradboost    0 | 0.213      203       4        96      13
  gradboost    1 | 0.213        0     118         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4        98      10
  STACKING     1 |    .         0     118         3      64
  logit        0 | 0.331      196       7        93      11
  logit        1 | 0.331        7     115         8      63
  rf           0 | 0.457      203       1        97      13
  rf           1 | 0.457        0     121         4      61
  gradboost    0 | 0.213      203       4        96      13
  gradboost    1 | 0.213        0     118         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1597235
  rf             |      0.1829718
  gradboost      |      0.6573047

. pystacked, table

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       417      13         .       .
  STACKING     1 |    .         4     256         .       .
  logit        0 | 0.160      399      40         .       .
  logit        1 | 0.160       22     229         .       .
  rf           0 | 0.183      421       1         .       .
  rf           1 | 0.183        0     268         .       .
  gradboost    0 | 0.657      416      13         .       .
  gradboost    1 | 0.657        5     256         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5        98      11
  STACKING     1 |    .         2     117         3      63
  logit        0 | 0.367      196       7        93      11
  logit        1 | 0.367        7     115         8      63
  rf           0 | 0.197      203       1        96      13
  rf           1 | 0.197        0     121         5      61
  gradboost    0 | 0.436      203       4        96      13
  gradboost    1 | 0.436        0     118         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5        98      11
  STACKING     1 |    .         2     117         3      63
  logit        0 | 0.367      196       7        93      11
  logit        1 | 0.367        7     115         8      63
  rf           0 | 0.197      203       1        96      13
  rf           1 | 0.197        0     121         5      61
  gradboost    0 | 0.436      203       4        96      13
  gradboost    1 | 0.436        0     118         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       203       4       207      18
  STACKING     1 |    .         0     118        11     129
  logit        0 | 0.331      196       7       200      21
  logit        1 | 0.331        7     115        18     126
  rf           0 | 0.457      203       1       206      22
  rf           1 | 0.457        0     121        12     125
  gradboost    0 | 0.213      203       4       203      24
  gradboost    1 | 0.213        0     118        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1587431
  rf             |      0.1806092
  gradboost      |      0.6606477

. pystacked, table

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       417      13         .       .
  STACKING     1 |    .         4     256         .       .
  logit        0 | 0.159      399      40         .       .
  logit        1 | 0.159       22     229         .       .
  rf           0 | 0.181      421       1         .       .
  rf           1 | 0.181        0     268         .       .
  gradboost    0 | 0.661      416      13         .       .
  gradboost    1 | 0.661        5     256         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1178419
  rf             |      0.3414634
  gradboost      |      0.5406946

. pystacked, graph
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1178419
  rf             |      0.3414634
  gradboost      |      0.5406946

. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1597235
  rf             |      0.1829718
  gradboost      |      0.6573047

. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.197      203       1       206      22
  rf           1 | 0.197        0     121        12     125
  gradboost    0 | 0.436      203       4       203      24
  gradboost    1 | 0.436        0     118        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3673815
  rf             |      0.2115335
  gradboost      |      0.4210850

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.212      203       1       206      22
  rf           1 | 0.212        0     121        12     125
  gradboost    0 | 0.421      203       4       203      24
  gradboost    1 | 0.421        0     118        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5        98      11
  STACKING     1 |    .         2     117         3      63
  logit        0 | 0.367      196       7        93      11
  logit        1 | 0.367        7     115         8      63
  rf           0 | 0.212      203       1        96      13
  rf           1 | 0.212        0     121         5      61
  gradboost    0 | 0.421      203       4        96      13
  gradboost    1 | 0.421        0     118         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1597235
  rf             |      0.1829718
  gradboost      |      0.6573047

. pystacked, graph

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.212      203       1       206      22
  rf           1 | 0.212        0     121        12     125
  gradboost    0 | 0.421      203       4       203      24
  gradboost    1 | 0.421        0     118        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3673815
  rf             |      0.2115335
  gradboost      |      0.4210850

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample and Out-of-Sample
------------------------------------------------------------
  Method         | Weight      In-Sample       Out-of-Sample
                 |             0       1         0       1  
-----------------+------------------------------------------
  STACKING     0 |    .       201       5       206      19
  STACKING     1 |    .         2     117        12     128
  logit        0 | 0.367      196       7       200      21
  logit        1 | 0.367        7     115        18     126
  rf           0 | 0.212      203       1       206      22
  rf           1 | 0.212        0     121        12     125
  gradboost    0 | 0.421      203       4       203      24
  gradboost    1 | 0.421        0     118        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1587431
  rf             |      0.1806092
  gradboost      |      0.6606477

. pystacked, graph

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3673815
  rf             |      0.2115335
  gradboost      |      0.4210850

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365
Number of holdout observations:  365
Number of holdout observations:  365

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout
Number of holdout observations:  365

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)
Number of holdout observations:  365

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. pystacked, graph holdout
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3305008
  rf             |      0.4567575
  gradboost      |      0.2127417

. pystacked, graph holdout
Number of holdout observations:  365

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. pystacked, graph holdout
Number of holdout observations:  365

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.0'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                 
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'0.24.0'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                 
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3672354
  rf             |      0.1966759
  gradboost      |      0.4360887

. pystacked, graph holdout
Number of holdout observations:  365
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0
> .1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decr
> ease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937);
>  warm_start = False; ccp_alpha = 0; max_samples = 10; 

Single base learner: no stacking done.
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0
> .1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decr
> ease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937);
>  warm_start = False; ccp_alpha = 0; max_samples = 10; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 
> 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3
> ; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = s
> qrt; max_leaf_nodes = 4; warm_start = False; validation_fraction = 0.15; n_iter_no_change = None;
>  tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

Stacking weights:
---------------------------------------

  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   
. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 
> 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3
> ; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = s
> qrt; max_leaf_nodes = 4; warm_start = False; validation_fraction = 0.15; n_iter_no_change = None;
>  tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter =
>  90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_r
> atios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_j
> obs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90
> ; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter =
>  90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_r
> atios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_j
> obs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = Tr
> ue; tol = 0.01; cache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = Ra
> ndomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                     
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90
> ; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = Tr
> ue; tol = 0.01; cache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = Ra
> ndomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                     
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.2'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                 
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; in
> tercept_scaling = 1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter
>  = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter
>  = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = R
> andomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_ite
> r = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = 
> RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedma
> n_mse; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth =
>  3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features =
>  sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_
> change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; in
> tercept_scaling = 1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter
>  = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter
>  = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = R
> andomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_ite
> r = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = 
> RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = ls; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedman_mse; min_
> samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_imp
> urity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = sqrt; alph
> a = 0.8; max_leaf_nodes = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_change = No
> ne; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_le
> af = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_d
> ecrease = 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT1
> 9937); warm_start = True; ccp_alpha = 0; max_samples = None; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = mse; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; 
> min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_decrease = 
> 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT19937); war
> m_start = True; ccp_alpha = 0; max_samples = None; 

Single base learner: no stacking done.
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0
> .1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decr
> ease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937);
>  warm_start = False; ccp_alpha = 0; max_samples = 10; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.0'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check stdscaler default with regularized linear learners                            ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. pystacked medv $xvars, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'0.24.0'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check stdscaler default with regularized linear learners                            ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. pystacked medv $xvars, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 
> 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3
> ; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = s
> qrt; max_leaf_nodes = 4; warm_start = False; validation_fraction = 0.15; n_iter_no_change = None;
>  tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9579246
  lassocv        |      0.0420754

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars, method(gradboost lassocv) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter =
>  90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_r
> atios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9579246
  lassocv        |      0.0420754

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars, method(gradboost lassocv) pipe2(nostdscaler)
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_j
> obs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90
> ; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = Tr
> ue; tol = 0.01; cache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = Ra
> ndomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                     
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

.         
. pystacked medv $xvars || m(gradboost) || m(lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

.         
. pystacked medv $xvars || m(gradboost) || m(lassocv)   
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; in
> tercept_scaling = 1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter
>  = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter
>  = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = R
> andomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_ite
> r = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = 
> RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedma
> n_mse; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth =
>  3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features =
>  sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_
> change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.1'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                 
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_le
> af = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_d
> ecrease = 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT1
> 9937); warm_start = True; ccp_alpha = 0; max_samples = None; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9672068
  lassocv        |      0.0327932

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars || m(gradboost) || m(lassocv) pipe(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9672068
  lassocv        |      0.0327932

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars || m(gradboost) || m(lassocv) pipe(nostdscaler)
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0
> .1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decr
> ease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937);
>  warm_start = False; ccp_alpha = 0; max_samples = 10; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.2'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check stdscaler default with regularized linear learners                            ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. pystacked medv $xvars, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

. 
. 
. *******************************************************************************
. *** xvar option                                                                                  
>                                        ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. global xuse c.(crim lstat)##c.(crim lstat)

. global xall c.(crim-lstat)##c.(crim-lstat)

. 
. set seed 789

. pystacked medv $xuse, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

. 
. 
. *******************************************************************************
. *** xvar option                                                                                  
>                                        ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. global xuse c.(crim lstat)##c.(crim lstat)

. global xall c.(crim-lstat)##c.(crim-lstat)

. 
. set seed 789

. pystacked medv $xuse, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9579246
  lassocv        |      0.0420754

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars, method(gradboost lassocv) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb

.  
. set seed 789

. pystacked medv $xall, method(gradboost lassocv) xvars1($xuse) xvars2($xuse) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 
> 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3
> ; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = s
> qrt; max_leaf_nodes = 4; warm_start = False; validation_fraction = 0.15; n_iter_no_change = None;
>  tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb

.  
. set seed 789

. pystacked medv $xall, method(gradboost lassocv) xvars1($xuse) xvars2($xuse) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter =
>  90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_r
> atios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_j
> obs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90
> ; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = Tr
> ue; tol = 0.01; cache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = Ra
> ndomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                     
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb2

. 
. set seed 789

. pystacked medv $xall || method(gradboost) xvars($xuse) || m(lassocv) xvars($xuse),  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

.         
. pystacked medv $xvars || m(gradboost) || m(lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb2

. 
. set seed 789

. pystacked medv $xall || method(gradboost) xvars($xuse) || m(lassocv) xvars($xuse),  
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; in
> tercept_scaling = 1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter
>  = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter
>  = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = R
> andomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_ite
> r = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = 
> RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedma
> n_mse; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth =
>  3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features =
>  sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_
> change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb3

. 
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1($xuse) xvars2($xuse)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_le
> af = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_d
> ecrease = 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT1
> 9937); warm_start = True; ccp_alpha = 0; max_samples = None; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb3

. 
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1($xuse) xvars2($xuse)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9672068
  lassocv        |      0.0327932

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars || m(gradboost) || m(lassocv) pipe(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb4

. 
. ** this should be different
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb4

. 
. ** this should be different
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.1'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check stdscaler default with regularized linear learners                            ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. pystacked medv $xvars, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

. 
. 
. *******************************************************************************
. *** xvar option                                                                                  
>                                        ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. global xuse c.(crim lstat)##c.(crim lstat)

. global xall c.(crim-lstat)##c.(crim-lstat)

. 
. set seed 789

. pystacked medv $xuse, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb5

. 
. assert reldif(xb,xb2)<1e-5

. assert reldif(xb,xb3)<1e-5

. assert reldif(xb,xb4)<1e-5

. assert xb!=xb5

. 
. 
. *******************************************************************************
. *** xvar vs pipeline                                                                             
>                                ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars2(c.(crim-lstat)##c.(crim-lstat))  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb5

. 
. assert reldif(xb,xb2)<1e-5

. assert reldif(xb,xb3)<1e-5

. assert reldif(xb,xb4)<1e-5

. assert xb!=xb5

. 
. 
. *******************************************************************************
. *** xvar vs pipeline                                                                             
>                                ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars2(c.(crim-lstat)##c.(crim-lstat))  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb

.  
. set seed 789

. pystacked medv $xall, method(gradboost lassocv) xvars1($xuse) xvars2($xuse) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9579246
  lassocv        |      0.0420754

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars, method(gradboost lassocv) pipe2(nostdscaler)

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb2

. 
. set seed 789

. pystacked medv $xall || method(gradboost) xvars($xuse) || m(lassocv) xvars($xuse),  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

.         
. pystacked medv $xvars || m(gradboost) || m(lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb3

. 
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1($xuse) xvars2($xuse)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9672068
  lassocv        |      0.0327932

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars || m(gradboost) || m(lassocv) pipe(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb4

. 
. ** this should be different
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb5

. 
. assert reldif(xb,xb2)<1e-5

. assert reldif(xb,xb3)<1e-5

. assert reldif(xb,xb4)<1e-5

. assert xb!=xb5

. 
. 
. *******************************************************************************
. *** xvar vs pipeline                                                                             
>                                ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars2(c.(crim-lstat)##c.(crim-lstat))  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

. 
. 
. *******************************************************************************
. *** xvar option                                                                                  
>                                        ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. global xuse c.(crim lstat)##c.(crim lstat)

. global xall c.(crim-lstat)##c.(crim-lstat)

. 
. set seed 789

. pystacked medv $xuse, method(gradboost lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3673815
  rf             |      0.2115335
  gradboost      |      0.4210850

. pystacked, graph holdout
Number of holdout observations:  365

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb

.  
. set seed 789

. pystacked medv $xall, method(gradboost lassocv) xvars1($xuse) xvars2($xuse) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb2

. 
. set seed 789

. pystacked medv $xall || method(gradboost) xvars($xuse) || m(lassocv) xvars($xuse),  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb3

. 
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1($xuse) xvars2($xuse)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb4

. 
. ** this should be different
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb5

. 
. assert reldif(xb,xb2)<1e-5

. assert reldif(xb,xb3)<1e-5

. assert reldif(xb,xb4)<1e-5

. assert xb!=xb5

. 
. 
. *******************************************************************************
. *** xvar vs pipeline                                                                             
>                                ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars2(c.(crim-lstat)##c.(crim-lstat))  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160030
  lassocv        |      0.0839970

. predict double xb1

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) pipe2(poly2) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160030
  lassocv        |      0.0839970

. predict double xb1

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) pipe2(poly2) 

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.0'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                 
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160030
  lassocv        |      0.0839970

. predict double xb1

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) pipe2(poly2) 
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0
> .1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decr
> ease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937);
>  warm_start = False; ccp_alpha = 0; max_samples = 10; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 
> 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3
> ; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = s
> qrt; max_leaf_nodes = 4; warm_start = False; validation_fraction = 0.15; n_iter_no_change = None;
>  tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter =
>  90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_r
> atios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_j
> obs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90
> ; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = Tr
> ue; tol = 0.01; cache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = Ra
> ndomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                     
>                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; in
> tercept_scaling = 1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter
>  = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = aut
> o; learning_rate = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = 
> False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; mo
> mentum = 0.8; nesterovs_momentum = True; early_stopping = False; validation_fraction = 0.15; beta
> _1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter
>  = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = R
> andomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_ite
> r = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = 
> RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedma
> n_mse; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth =
>  3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features =
>  sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_
> change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_le
> af = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_d
> ecrease = 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT1
> 9937); warm_start = True; ccp_alpha = 0; max_samples = None; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160031
  lassocv        |      0.0839969

. predict double xb2

. 
. assert reldif(xb1,xb2)<1e-5

. 
. 
. *******************************************************************************
. *** voting                                                                                       
>                                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160031
  lassocv        |      0.0839969

. predict double xb2

. 
. assert reldif(xb1,xb2)<1e-5

. 
. 
. *******************************************************************************
. *** voting                                                                                       
>                                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160030
  lassocv        |      0.0839970

. predict double xb1

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) pipe2(poly2) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.3
*! last edited: 18Aug2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.0'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check stdscaler default with regularized linear learners                            ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. pystacked medv $xvars, method(gradboost lassocv)   
(11 vars, 97 obs)

. 
. global xvars lcavol-pgg

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)
(11 vars, 97 obs)

. 
. global xvars lcavol-pgg

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

. assert _rc == 198                                                

.                                         
. *******************************************************************************
. *** check pipeline                                                                               
>                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

. assert _rc == 198                                                

.                                         
. *******************************************************************************
. *** check pipeline                                                                               
>                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf ) ///
>                                                  pipe1(poly2) pipe2(poly2 nostdscaler) pipe3(poly
> 2)  
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf ) ///
>                                                  pipe1(poly2) pipe2(poly2 nostdscaler) pipe3(poly
> 2)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9566345
  lassocv        |      0.0433655

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars, method(gradboost lassocv) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

.         
. pystacked medv $xvars || m(gradboost) || m(lassocv)   

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1373335
  lassoic        |      0.8166779
  rf             |      0.0459886

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe3) : "poly2"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe2) : "poly2"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe1) : "poly2"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict a, transf

. 
.  
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic  rf ) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1373094
  lassoic        |      0.8165431
  rf             |      0.0461475

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe3) : "poly2"
             e(pyopt3) : "{'n_estimators':100,'criterion':'mse','max_depth':None,'min_samples_s.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe2) : "poly2"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe1) : "poly2"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "0.24.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict a, transf

. 
.  
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic  rf ) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160031
  lassocv        |      0.0839969

. predict double xb2

. 
. assert reldif(xb1,xb2)<1e-5

. 
. 
. *******************************************************************************
. *** voting                                                                                       
>                                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab clear
(11 vars, 97 obs)

. 
. global xvars lcavol-pgg

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9667921
  lassocv        |      0.0332079

. di "`e(pipe2)'"
stdscaler

. assert "`e(pipe2)'"=="stdscaler"

. 
. pystacked medv $xvars || m(gradboost) || m(lassocv) pipe(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

. assert _rc == 198                                                

.                                         
. *******************************************************************************
. *** check pipeline                                                                               
>                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf ) ///
>                                                  pipe1(poly2) pipe2(poly2 nostdscaler) pipe3(poly
> 2)  
note: svi omitted because of collinearity.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1380955
  lassoic        |      0.8136403
  rf             |      0.0482642

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe3) : "passthrough"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe2) : "passthrough"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph lcp gleason pgg45 __000001 __000002 __000003 .."
              e(pipe1) : "passthrough"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict b, transf

. list lpsa a* b* if _n <= 10

     +-----------------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2         b3 |
     |-----------------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799    1.19435   .3325487   .2531799    1.19435   .3325487 |
  2. | -.1625189    58   .5338573   1.205396   .0659286   .5338573   1.205396   .0659286 |
  3. | -.1625189    74   .2774684   1.251625   .3647012   .2774684   1.251625   .3647012 |
  4. | -.1625189    58   .4093789   1.101081   .0859689   .4093789   1.101081   .0859689 |
  5. |  .3715636    62   1.388298   2.006096   .6633989   1.388298   2.006096   .6633989 |
     |-----------------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.149503   .4205081   .6148925   1.149503   .4205081 |
  7. |  .7654678    64   1.843947   2.014224   1.027373   1.843947   2.014224   1.027373 |
  8. |  .8544153    58   1.820537   2.018032   1.162384   1.820537   2.018032   1.162384 |
  9. |  1.047319    47   1.383648   1.377017   .7764618   1.383648   1.377017   .7764618 |
 10. |  1.047319    63   .8287085   1.710201   1.236331   .8287085   1.710201   1.236331 |
     +-----------------------------------------------------------------------------------+

. 
. assert reldif(a1,b1)<1e-5

. assert reldif(a2,b2)<1e-5

. 
. *******************************************************************************
. *** check that xvar() subsetting works                                                           
>                ***
. *******************************************************************************
. 
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
note: svi omitted because of collinearity.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1373859
  lassoic        |      0.8155965
  rf             |      0.0470176

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe3) : "passthrough"
             e(pyopt3) : "{'n_estimators':100,'criterion':'mse','max_depth':None,'min_samples_s.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe2) : "passthrough"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph lcp gleason pgg45 __000001 __000002 __000003 .."
              e(pipe1) : "passthrough"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "0.24.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict b, transf

. list lpsa a* b* if _n <= 10

     +-----------------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2         b3 |
     |-----------------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799    1.19435   .3325487   .2531799    1.19435   .3325487 |
  2. | -.1625189    58   .5338573   1.205396   .0659286   .5338573   1.205396   .0659286 |
  3. | -.1625189    74   .2774684   1.251625   .3647012   .2774684   1.251625   .3647012 |
  4. | -.1625189    58   .4093789   1.101081   .0859689   .4093789   1.101081   .0859689 |
  5. |  .3715636    62   1.388298   2.006096   .6633989   1.388298   2.006096   .6633989 |
     |-----------------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.149503   .4205081   .6148925   1.149503   .4205081 |
  7. |  .7654678    64   1.843947   2.014224   1.027373   1.843947   2.014224   1.027373 |
  8. |  .8544153    58   1.820537   2.018032   1.162384   1.820537   2.018032   1.162384 |
  9. |  1.047319    47   1.383648   1.377017   .7764618   1.383648   1.377017   .7764618 |
 10. |  1.047319    63   .8287085   1.710201   1.236331   .8287085   1.710201   1.236331 |
     +-----------------------------------------------------------------------------------+

. 
. assert reldif(a1,b1)<1e-5

. assert reldif(a2,b2)<1e-5

. 
. *******************************************************************************
. *** check that xvar() subsetting works                                                           
>                ***
. *******************************************************************************
. 
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv crim lstat, method(gradboost lassocv) pyseed(-1)
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv crim lstat, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000
  lassocv        |      0.0000000

. di "`e(pipe2)'"
passthrough

. assert "`e(pipe2)'"=="passthrough"

. 
. 
. *******************************************************************************
. *** xvar option                                                                                  
>                                        ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. global xuse c.(crim lstat)##c.(crim lstat)

. global xall c.(crim-lstat)##c.(crim-lstat)

. 
. set seed 789

. pystacked medv $xuse, method(gradboost lassocv)   

Stacking weights:

--------------------------------------
  Method         |      Weight
Stacking weights:
-----------------+---------------------
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429
  gradboost      |      0.6968571
  lassocv        |      0.3031429


. predict double xb
. predict double xb

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat) pyseed
> (-1)
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat) pyseed
> (-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb

.  
. set seed 789

. pystacked medv $xall, method(gradboost lassocv) xvars1($xuse) xvars2($xuse) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb2

. 
. set seed 789

. pystacked medv crim-lstat || method(gradboost) xvars(crim lstat) || m(lassocv) xvars(crim lstat),
>  pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb2

. 
. set seed 789

. pystacked medv crim-lstat || method(gradboost) xvars(crim lstat) || m(lassocv) xvars(crim lstat),
>  pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0992286
  lassoic        |      0.9007714
  rf             |      0.0000000

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe3) : "poly2"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe2) : "poly2"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe1) : "poly2"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.2"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict a, transf

. 
.  
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic  rf ) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.114072   27.114072   27.114072 |
  2. | 22.895686   22.895686   22.895686 |
  3. | 33.639119   33.639119   33.639119 |
  4. | 34.787589   34.787589   34.787589 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *** with factor variables
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.114072   27.114072   27.114072 |
  2. | 22.895686   22.895686   22.895686 |
  3. | 33.639119   33.639119   33.639119 |
  4. | 34.787589   34.787589   34.787589 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *** with factor variables
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv i.rad##c.crim, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb2

. 
. set seed 789

. pystacked medv $xall || method(gradboost) xvars($xuse) || m(lassocv) xvars($xuse),  
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv i.rad##c.crim, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9160031
  lassocv        |      0.0839969

. predict double xb2

. 
. assert reldif(xb1,xb2)<1e-5

. 
. 
. *******************************************************************************
. *** voting                                                                                       
>                                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb3

. 
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1($xuse) xvars2($xuse)  
(11 vars, 97 obs)

. 
. global xvars lcavol-pgg

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat), method(gradboost lassocv) xvars1(i.rad##c.crim) xvars2(i.ra
> d##c.crim) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat), method(gradboost lassocv) xvars1(i.rad##c.crim) xvars2(i.ra
> d##c.crim) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

. assert _rc == 198                                                

.                                         
. *******************************************************************************
. *** check pipeline                                                                               
>                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.5376461
  lassocv        |      0.4623539

. predict double xb4

. 
. ** this should be different
. set seed 789

. pystacked medv crim, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat)   
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf ) ///
>                                                  pipe1(poly2) pipe2(poly2 nostdscaler) pipe3(poly
> 2)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb2

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat) || method(gradboost) xvars(i.rad##c.crim) || m(lassocv) xvar
> s(i.rad##c.crim), pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb2

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat) || method(gradboost) xvars(i.rad##c.crim) || m(lassocv) xvar
> s(i.rad##c.crim), pyseed(-1)
note: svi omitted because of collinearity.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0873970
  lassoic        |      0.8679799
  rf             |      0.0446230

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe3) : "passthrough"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe2) : "passthrough"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph lcp gleason pgg45 __000001 __000002 __000003 .."
              e(pipe1) : "passthrough"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.2"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict b, transf

. list lpsa a* b* if _n <= 10

     +-----------------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2         b3 |
     |-----------------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799   1.079373   .3325487   .2531799   1.079373   .3325487 |
  2. | -.1625189    58   .5338573   .9922831   .0659286   .5338573   .9922831   .0659286 |
  3. | -.1625189    74   .2774684   .7602873   .3647012   .2774684   .7602873   .3647012 |
  4. | -.1625189    58   .4093789   .8741754   .0859689   .4093789   .8741754   .0859689 |
  5. |  .3715636    62   1.388298   1.827831   .6633989   1.388298   1.827831   .6633989 |
     |-----------------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.051359   .4205081   .6148925   1.051359   .4205081 |
  7. |  .7654678    64   1.843947    1.93333   1.027373   1.843947    1.93333   1.027373 |
  8. |  .8544153    58   1.820537   1.894149   1.162384   1.820537   1.894149   1.162384 |
  9. |  1.047319    47   1.383648   1.367152   .7764618   1.383648   1.367152   .7764618 |
 10. |  1.047319    63   .8287085   1.473098   1.236331   .8287085   1.473098   1.236331 |
     +-----------------------------------------------------------------------------------+

. 
. assert reldif(a1,b1)<1e-5

. assert reldif(a2,b2)<1e-5

. 
. *******************************************************************************
. *** check that xvar() subsetting works                                                           
>                ***
. *******************************************************************************
. 
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv crim lstat, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb5

. 
. assert reldif(xb,xb2)<1e-5

. assert reldif(xb,xb3)<1e-5

. assert reldif(xb,xb4)<1e-5

. assert xb!=xb5

. 
. 
. *******************************************************************************
. *** xvar vs pipeline                                                                             
>                                ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

.         
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars2(c.(crim-lstat)##c.(crim-lstat))  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat) pyseed
> (-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.524536   27.524536   27.524536 |
  2. | 26.063472   26.063472   26.063472 |
  3. | 29.877218   29.877218   29.877218 |
  4. | 30.183503   30.183503   30.183503 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *******************************************************************************
. *** try various combinations of estimators                                                       
>                ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.524536   27.524536   27.524536 |
  2. | 26.063472   26.063472   26.063472 |
  3. | 29.877218   29.877218   29.877218 |
  4. | 30.183503   30.183503   30.183503 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *******************************************************************************
. *** try various combinations of estimators                                                       
>                ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb2

. 
. set seed 789

. pystacked medv crim-lstat || method(gradboost) xvars(crim lstat) || m(lassocv) xvars(crim lstat),
>  pyseed(-1)
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2) finalest(singlebest)
  5. }
ols lassocv gradboost nnet
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2) finalest(singlebest)
  5. }
ols lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0992286
  lassoic        |      0.9007714
  rf             |      0.0000000

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe3) : "poly2"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe2) : "poly2"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe1) : "poly2"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.1"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict a, transf

. 
.  
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic  rf ) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.114072   27.114072   27.114072 |
  2. | 22.895686   22.895686   22.895686 |
  3. | 33.639119   33.639119   33.639119 |
  4. | 34.787589   34.787589   34.787589 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *** with factor variables
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv i.rad##c.crim, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat), method(gradboost lassocv) xvars1(i.rad##c.crim) xvars2(i.ra
> d##c.crim) pyseed(-1)
note: svi omitted because of collinearity.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0873970
  lassoic        |      0.8679799
  rf             |      0.0446230

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe3) : "passthrough"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe2) : "passthrough"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph lcp gleason pgg45 __000001 __000002 __000003 .."
              e(pipe1) : "passthrough"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.1"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict b, transf

. list lpsa a* b* if _n <= 10

     +-----------------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2         b3 |
     |-----------------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799   1.079373   .3325487   .2531799   1.079373   .3325487 |
  2. | -.1625189    58   .5338573   .9922831   .0659286   .5338573   .9922831   .0659286 |
  3. | -.1625189    74   .2774684   .7602873   .3647012   .2774684   .7602873   .3647012 |
  4. | -.1625189    58   .4093789   .8741754   .0859689   .4093789   .8741754   .0859689 |
  5. |  .3715636    62   1.388298   1.827831   .6633989   1.388298   1.827831   .6633989 |
     |-----------------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.051359   .4205081   .6148925   1.051359   .4205081 |
  7. |  .7654678    64   1.843947    1.93333   1.027373   1.843947    1.93333   1.027373 |
  8. |  .8544153    58   1.820537   1.894149   1.162384   1.820537   1.894149   1.162384 |
  9. |  1.047319    47   1.383648   1.367152   .7764618   1.383648   1.367152   .7764618 |
 10. |  1.047319    63   .8287085   1.473098   1.236331   .8287085   1.473098   1.236331 |
     +-----------------------------------------------------------------------------------+

. 
. assert reldif(a1,b1)<1e-5

. assert reldif(a2,b2)<1e-5

. 
. *******************************************************************************
. *** check that xvar() subsetting works                                                           
>                ***
. *******************************************************************************
. 
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv crim lstat, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb2

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat) || method(gradboost) xvars(i.rad##c.crim) || m(lassocv) xvar
> s(i.rad##c.crim), pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat) pyseed
> (-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.524536   27.524536   27.524536 |
  2. | 26.063472   26.063472   26.063472 |
  3. | 29.877218   29.877218   29.877218 |
  4. | 30.183503   30.183503   30.183503 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *******************************************************************************
. *** try various combinations of estimators                                                       
>                ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb2

. 
. set seed 789

. pystacked medv crim-lstat || method(gradboost) xvars(crim lstat) || m(lassocv) xvars(crim lstat),
>  pyseed(-1)
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2) finalest(singlebest)
  5. }
ols lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.114072   27.114072   27.114072 |
  2. | 22.895686   22.895686   22.895686 |
  3. | 33.639119   33.639119   33.639119 |
  4. | 34.787589   34.787589   34.787589 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *** with factor variables
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv i.rad##c.crim, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat), method(gradboost lassocv) xvars1(i.rad##c.crim) xvars2(i.ra
> d##c.crim) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0534320
  lassocv        |      0.9465680
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0534320
  lassocv        |      0.9465680
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb2

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat) || method(gradboost) xvars(i.rad##c.crim) || m(lassocv) xvar
> s(i.rad##c.crim), pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9309431
  lassocv        |      0.0690569

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.524536   27.524536   27.524536 |
  2. | 26.063472   26.063472   26.063472 |
  3. | 29.877218   29.877218   29.877218 |
  4. | 30.183503   30.183503   30.183503 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *******************************************************************************
. *** try various combinations of estimators                                                       
>                ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2) finalest(singlebest)
  5. }
ols lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9132685
  lassocv        |      0.0867315

. predict double xb1

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) pipe2(poly2) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0534320
  lassocv        |      0.9465680
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0534320
  lassocv        |      0.9465680
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0835407
  lassoic        |      0.5199784
  gradboost      |      0.3964809
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0826371
  lassoic        |      0.5220889
  gradboost      |      0.3952739
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0424691
  ridgecv        |      0.9575309
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0424691
  ridgecv        |      0.9575309
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ridgecv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ridgecv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9132685
  lassocv        |      0.0867315

. predict double xb2

. 
. assert reldif(xb1,xb2)<1e-5

. 
. 
. *******************************************************************************
. *** voting                                                                                       
>                                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet
(11 vars, 97 obs)

. 
. global xvars lcavol-pgg

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0572694
  lassoic        |      0.7907716
  gradboost      |      0.1519590
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

. assert _rc == 198                                                

.                                         
. *******************************************************************************
. *** check pipeline                                                                               
>                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols ridgecv gradboost nnet
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf ) ///
>                                                  pipe1(poly2) pipe2(poly2 nostdscaler) pipe3(poly
> 2)  

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0424691
  ridgecv        |      0.9575309
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0557003
  elasticcv      |      0.9268604
  gradboost      |      0.0174393
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0557003
  elasticcv      |      0.9268604
  gradboost      |      0.0174393
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ridgecv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0992286
  lassoic        |      0.9007714
  rf             |      0.0000000

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe3) : "poly2"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe2) : "poly2"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph svi lcp gleason pgg45"
              e(pipe1) : "poly2"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict a, transf

. 
.  
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic  rf ) pipe2(nostdscaler)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0572694
  lassoic        |      0.7907716
  gradboost      |      0.1519590
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0424691
  ridgecv        |      0.9575309
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm
note: svi omitted because of collinearity.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0873970
  lassoic        |      0.8679799
  rf             |      0.0446230

. ereturn list

scalars:
                  e(N) =  97
             e(mcount) =  3

macros:
             e(xvars3) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe3) : "passthrough"
             e(pyopt3) : "{'n_estimators':100,'criterion':'squared_error','max_depth':None,'min.."
            e(method3) : "rf"
             e(xvars2) : "lcavol lweight age lbph svi lcp gleason pgg45 __000001 __000002 __000.."
              e(pipe2) : "passthrough"
             e(pyopt2) : "{'criterion':'aic','fit_intercept':True,'max_iter':500,'positive':Fal.."
            e(method2) : "lassoic"
             e(xvars1) : "lcavol lweight age lbph lcp gleason pgg45 __000001 __000002 __000003 .."
              e(pipe1) : "passthrough"
             e(pyopt1) : "{'fit_intercept':True,'positive':False}"
            e(method1) : "ols"
               e(type) : "reg"
             e(depvar) : "lpsa"
            e(predict) : "pystacked_p"
                e(cmd) : "pystacked"
         e(python_ver) : "3.9.13 (main, May 24 2022, 21:28:12) 
[Clang 12.0.0 (clang-1200.0.32..."
          e(scipy_ver) : "1.9.0"
          e(numpy_ver) : "1.23.2"
        e(sklearn_ver) : "1.1.0"
           e(base_est) : "ols lassoic rf"

matrices:
            e(weights) :  3 x 1

functions:
             e(sample)   

. predict b, transf

. list lpsa a* b* if _n <= 10

     +-----------------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2         b3 |
     |-----------------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799   1.079373   .3325487   .2531799   1.079373   .3325487 |
  2. | -.1625189    58   .5338573   .9922831   .0659286   .5338573   .9922831   .0659286 |
  3. | -.1625189    74   .2774684   .7602873   .3647012   .2774684   .7602873   .3647012 |
  4. | -.1625189    58   .4093789   .8741754   .0859689   .4093789   .8741754   .0859689 |
  5. |  .3715636    62   1.388298   1.827831   .6633989   1.388298   1.827831   .6633989 |
     |-----------------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.051359   .4205081   .6148925   1.051359   .4205081 |
  7. |  .7654678    64   1.843947    1.93333   1.027373   1.843947    1.93333   1.027373 |
  8. |  .8544153    58   1.820537   1.894149   1.162384   1.820537   1.894149   1.162384 |
  9. |  1.047319    47   1.383648   1.367152   .7764618   1.383648   1.367152   .7764618 |
 10. |  1.047319    63   .8287085   1.473098   1.236331   .8287085   1.473098   1.236331 |
     +-----------------------------------------------------------------------------------+

. 
. assert reldif(a1,b1)<1e-5

. assert reldif(a2,b2)<1e-5

. 
. *******************************************************************************
. *** check that xvar() subsetting works                                                           
>                ***
. *******************************************************************************
. 
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ridgecv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost nnet
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv crim lstat, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0557003
  elasticcv      |      0.9268604
  gradboost      |      0.0174393
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb

. 
. set seed 789

. pystacked medv crim-lstat, method(gradboost lassocv) xvars1(crim lstat) xvars2(crim lstat) pyseed
> (-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb2

. 
. set seed 789

. pystacked medv crim-lstat || method(gradboost) xvars(crim lstat) || m(lassocv) xvars(crim lstat),
>  pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.6968571
  lassocv        |      0.3031429

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.114072   27.114072   27.114072 |
  2. | 22.895686   22.895686   22.895686 |
  3. | 33.639119   33.639119   33.639119 |
  4. | 34.787589   34.787589   34.787589 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *** with factor variables
. 
. insheet using https://statalasso.github.io/dta/housing.csv, clear
(14 vars, 506 obs)

. 
. set seed 789

. pystacked medv i.rad##c.crim, method(gradboost lassocv) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0535929
  elasticcv      |      0.9067297
  gradboost      |      0.0187588
  svm            |      0.0209185

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0535929
  elasticcv      |      0.9067297
  gradboost      |      0.0187588
  svm            |      0.0209185

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0557003
  elasticcv      |      0.9268604
  gradboost      |      0.0174393
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9287589
  lassocv        |      0.0712411

. predict double xb

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat), method(gradboost lassocv) xvars1(i.rad##c.crim) xvars2(i.ra
> d##c.crim) pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9287589
  lassocv        |      0.0712411

. predict double xb2

. 
. set seed 789

. pystacked medv i.rad##c.(crim-lstat) || method(gradboost) xvars(i.rad##c.crim) || m(lassocv) xvar
> s(i.rad##c.crim), pyseed(-1)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0535929
  elasticcv      |      0.9067297
  gradboost      |      0.0187588
  svm            |      0.0209185

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      0.9287589
  lassocv        |      0.0712411

. predict double xb3

. list xb* if _n<5

     +-----------------------------------+
     |        xb         xb2         xb3 |
     |-----------------------------------|
  1. | 27.519168   27.519168   27.519168 |
  2. | 26.061522   26.061522   26.061522 |
  3. |  29.86632    29.86632    29.86632 |
  4. | 30.175247   30.175247   30.175247 |
     +-----------------------------------+

. assert reldif(xb,xb2)<10e-9

. assert reldif(xb,xb3)<10e-9

. 
. 
. *******************************************************************************
. *** try various combinations of estimators                                                       
>                ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0676987
  elasticcv      |      0.7585643
  gradboost      |      0.0327074
  linsvm         |      0.1410297

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0535929
  elasticcv      |      0.9067297
  gradboost      |      0.0187588
  svm            |      0.0209185

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0129071
  elasticcv      |      0.0984761
  gradboost      |      0.1058145
  linsvm         |      0.7828023
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2) finalest(singlebest)
  5. }
ols lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0961638
  elasticcv      |      0.1699483
  gradboost      |      0.0200817
  linsvm         |      0.7138061

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0534161
  lassocv        |      0.9465839
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0732438
  elasticcv      |      0.5626661
  gradboost      |      0.0925295
  linsvm         |      0.2715606

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8253543
  lassoic        |      0.1746457
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .87571818 |
  2. | .82913236 |
  3. |  .5612358 |
  4. | .69263341 |
  5. | 1.7820582 |
     |-----------|
  6. | .88598204 |
  7. | 1.9229353 |
  8. | 2.1160923 |
  9. | 1.2697235 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                                         *
> **
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8253543
  lassoic        |      0.1746457
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .87571816 |
  2. | .82913234 |
  3. | .56123576 |
  4. | .69263338 |
  5. | 1.7820582 |
     |-----------|
  6. | .88598203 |
  7. | 1.9229353 |
  8. | 2.1160923 |
  9. | 1.2697235 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                                         *
> **
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8253543
  lassoic        |      0.1746457
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8253543
  lassoic        |      0.1746457
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols lassocv rf nnet
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .82398307 |
  2. | .76423015 |
  3. |  .4476866 |
  4. | .62329328 |
  5. | 1.7332726 |
     |-----------|
  6. |  .8442738 |
  7. | 1.9008336 |
  8. | 2.1311292 |
  9. | 1.2537383 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                                         *
> **
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .82398307 |
  2. | .76423015 |
  3. |  .4476866 |
  4. | .62329328 |
  5. | 1.7332726 |
     |-----------|
  6. |  .8442738 |
  7. | 1.9008336 |
  8. | 2.1311292 |
  9. | 1.2537383 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                                         *
> **
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000
  nnet           |      0.0000000
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. pystacked, table

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.606             .
  ols            | 0.053       0.501             .
  lassocv        | 0.947       0.617             .
  rf             | 0.000       0.286             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      1.0000000
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0573238
  lassoic        |      0.7913622
  gradboost      |      0.1513139
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. pystacked, table

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.606             .
  ols            | 0.053       0.501             .
  lassocv        | 0.947       0.617             .
  rf             | 0.000       0.287             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0424691
  ridgecv        |      0.9575309
  gradboost      |      0.0000000
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  ridgecv        |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. pystacked, table

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.606             .
  ols            | 0.053       0.501             .
  lassocv        | 0.947       0.617             .
  rf             | 0.000       0.286             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0558108
  elasticcv      |      0.9281066
  gradboost      |      0.0160826
  nnet           |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. pystacked, table

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.606             .
  ols            | 0.053       0.501             .
  lassocv        | 0.947       0.617             .
  rf             | 0.000       0.286             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0536994
  elasticcv      |      0.9079436
  gradboost      |      0.0174494
  svm            |      0.0209076

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.701
  ols            | 0.000       0.317         5.840
  lassocv        | 0.000       0.549         0.720
  rf             | 1.000       0.257         0.701

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.701
  ols            | 0.000       0.317         5.840
  lassocv        | 0.000       0.549         0.720
  rf             | 1.000       0.257         0.701

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.701
  ols            | 0.000       0.317         5.840
  lassocv        | 0.000       0.549         0.720
  rf             | 1.000       0.257         0.701

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0558108
  elasticcv      |      0.9281065
  gradboost      |      0.0160828
  linsvm         |      0.0000000

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.701
  ols            | 0.000       0.317         5.840
  lassocv        | 0.000       0.549         0.720
  rf             | 1.000       0.257         0.701

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  elasticcv      |      1.0000000
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .82398307 |
  2. | .76423015 |
  3. |  .4476866 |
  4. | .62329328 |
  5. | 1.7332726 |
     |-----------|
  6. |  .8442738 |
  7. | 1.9008336 |
  8. | 2.1311292 |
  9. | 1.2537383 |
     +-----------+

. 
. predict double t, transform  

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                                         *
> **
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) ||  if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) ||  if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.9779424
  lassoic        |      0.0220576
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.416         0.783
  ols            | 0.646       0.526         0.871
  lassocv        | 0.000       0.526         0.841
  rf             | 0.354       0.257         0.701

. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6468836
  lassocv        |      0.0000000
  rf             |      0.3531164

. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.417         0.783
  ols            | 0.647       0.526         0.871
  lassocv        | 0.000       0.526         0.841
  rf             | 0.353       0.257         0.701

. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) ||  if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.416         0.783
  ols            | 0.646       0.526         0.871
  lassocv        | 0.000       0.526         0.841
  rf             | 0.354       0.257         0.701

. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) ||  if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.416         0.783
  ols            | 0.646       0.526         0.871
  lassocv        | 0.000       0.526         0.841
  rf             | 0.354       0.257         0.701

. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. pystacked, table

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.606             .
  ols            | 0.053       0.501             .
  lassocv        | 0.947       0.617             .
  rf             | 0.000       0.286             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. // in-sample predictions
. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. // in-sample predictions
. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. // in-sample predictions
. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. // in-sample predictions
. pystacked, graph

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.701
  ols            | 0.000       0.317         5.840
  lassocv        | 0.000       0.549         0.720
  rf             | 1.000       0.257         0.701

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // in-sample predictions
. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // in-sample predictions
. pystacked, graph

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // in-sample predictions
. pystacked, graph
Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.257         0.703
  ols            | 0.000       0.317         5.320
  lassocv        | 0.000       0.549         0.711
  rf             | 1.000       0.257         0.703

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) ||  if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, table holdout(h1)
Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.416         0.783
  ols            | 0.646       0.526         0.871
  lassocv        | 0.000       0.526         0.841
  rf             | 0.354       0.257         0.701

. 
. *******************************************************************************
. *** check graph option                                                                           
>                                ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // in-sample predictions
. pystacked, graph
(11 vars, 97 obs)

. global xvars lcavol-pgg

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:   48

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:   48

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:   48

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0532191
  lassocv        |      0.9467809
  rf             |      0.0000000

. // in-sample predictions
. pystacked, graph

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:   48

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:   37

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:   37

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:   37

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2)

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:   37

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:   48

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  rf             |      1.0000000

. // in-sample predictions
. pystacked, graph

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
Number of holdout observations:   48

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
Number of holdout observations:   48

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:   48

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:   37
Number of holdout observations:   48

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:   48
Number of holdout observations:   48
Number of holdout observations:   48
Number of holdout observations:   48

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) || if _n<50 , ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6468836
  lassocv        |      0.0000000
  rf             |      0.3531164

. pystacked, graph holdout
Number of holdout observations:   48

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
Number of holdout observations:   48

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) || if _n<50 , ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) || if _n<50 , ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, graph holdout
Number of holdout observations:   48

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, graph holdout
Number of holdout observations:   48

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) || if _n<50 , ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, graph holdout
Number of holdout observations:   48

.  
. 
end of do-file

. 
. log close
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_024.txt
  log type:  text
 closed on:  18 Aug 2022, 23:22:20
---------------------------------------------------------------------------------------------------


. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassocv rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout

.  
. 
end of do-file

. 
. log close
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_100.txt
  log type:  text
 closed on:  18 Aug 2022, 23:22:24
---------------------------------------------------------------------------------------------------


.  
. 
end of do-file

. 
. log close
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_112.txt
  log type:  text
 closed on:  18 Aug 2022, 23:22:25
---------------------------------------------------------------------------------------------------


.  
. 
end of do-file

. 
. log close
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_111.txt
  log type:  text
 closed on:  18 Aug 2022, 23:22:29
---------------------------------------------------------------------------------------------------

Number of holdout observations:   48

. 
. // syntax 2
. pystacked lpsa $xvars || method(ols) || method(lassocv) || method(rf) || if _n<50 , ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.6462654
  lassocv        |      0.0000000
  rf             |      0.3537346

. pystacked, graph holdout
Number of holdout observations:   48

.  
. 
end of do-file

. 
. log close
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_110.txt
  log type:  text
 closed on:  18 Aug 2022, 23:22:52
---------------------------------------------------------------------------------------------------

. 
end of do-file
. 
end of do-file
. 
end of do-file
. 
end of do-file
. 
end of do-file
