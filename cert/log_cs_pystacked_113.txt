-------------------------------------------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_113.txt
  log type:  text
 opened on:   5 Mar 2023, 13:31:19

. 
. do "cs_pystacked_class.do"

. 
. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.6.1
*! last edited: 5mar2023
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.3'

. 
. tempfile testdata

. set seed 765

. global model v58 v1-v30

. insheet using https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, clear comma
(58 vars, 4,601 obs)

. sample 15
(3,911 observations deleted)

. gen u = runiform()

. gen train = u<0.5

. gen train2 = u<.75

. save `testdata'
file /var/folders/0w/r8yclchd52bfwbf8l00fkkrr0000gs/T//S_34906.000001 saved as .dta format

. 
. *******************************************************************************
. *** check that it works without default methods                                                         ***
. *******************************************************************************
. 
.  insheet using ///
>  https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, ///
>  clear comma
(58 vars, 4,601 obs)

. set seed 42

. gen train=runiform()

. replace train=train<.75
(4,601 real changes made)

.  pystacked v58 v1-v57 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0089558
  lassocv        |      0.0000000
  gradboost      |      0.9910442

. 
. *******************************************************************************
. *** check against SJ paper                                                                                                      ***
. *******************************************************************************
. 
.  insheet using ///
>  https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data, ///
>  clear comma
(58 vars, 4,601 obs)

. set seed 42

. gen train=runiform()

. replace train=train<.75
(4,601 real changes made)

.  
.  pystacked v58 v1-v57                           || ///
>     m(logit) pipe(poly2)                        || ///
>     m(gradboost) opt(n_estimators(600))         || ///
>     m(gradboost) opt(n_estimators(1000))        || ///
>     m(nnet) opt(hidden_layer_sizes(5 5))        || ///
>     m(nnet) opt(hidden_layer_sizes(5))          || ///
>     if train, type(class) njobs(8) backend(threading) 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  gradboost      |      0.4815155
  gradboost      |      0.3446655
  nnet           |      0.1131199
  nnet           |      0.0606992

.         
. mat W = e(weights)

. assert reldif(0.0011469,el(W,1,1))<0.01

. assert reldif(0.4806232,el(W,2,1))<0.01

. assert reldif(0.3456255,el(W,3,1))<0.01

. assert reldif( 0.1130183,el(W,4,1))<0.01

. assert reldif( 0.0595860,el(W,5,1))<0.01

.  
. 
. *******************************************************************************
. *** foldvar                                                                                                                                     ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. gen fid = 1 + (_n>345)

.         
. pystacked v58 v1 v2 v3, method(logit rf) foldvar(fid) type(class)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.3591150
  rf             |      0.6408850

. predict yb , basexb cvalid

. 
. logit v58 v1 v2 v3 if fid==1

Iteration 0:   log likelihood = -230.91815  
Iteration 1:   log likelihood = -221.30531  
Iteration 2:   log likelihood = -221.28762  
Iteration 3:   log likelihood = -221.28762  

Logistic regression                                     Number of obs =    345
                                                        LR chi2(3)    =  19.26
                                                        Prob > chi2   = 0.0002
Log likelihood = -221.28762                             Pseudo R2     = 0.0417

------------------------------------------------------------------------------
         v58 | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
          v1 |   2.022795   .6649857     3.04   0.002     .7194464    3.326143
          v2 |  -.0229183   .1105851    -0.21   0.836    -.2396612    .1938246
          v3 |     .49605     .20824     2.38   0.017     .0879071    .9041928
       _cons |  -.7599564   .1407462    -5.40   0.000    -1.035814    -.484099
------------------------------------------------------------------------------

. predict log1 if fid ==2
(option pr assumed; Pr(v58))
(345 missing values generated)

. logit v58 v1 v2 v3 if fid==2

Iteration 0:   log likelihood = -230.47022  
Iteration 1:   log likelihood = -217.54677  
Iteration 2:   log likelihood = -217.49653  
Iteration 3:   log likelihood = -217.49645  
Iteration 4:   log likelihood = -217.49645  

Logistic regression                                     Number of obs =    345
                                                        LR chi2(3)    =  25.95
                                                        Prob > chi2   = 0.0000
Log likelihood = -217.49645                             Pseudo R2     = 0.0563

------------------------------------------------------------------------------
         v58 | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
          v1 |   1.083844   .4417874     2.45   0.014     .2179562    1.949731
          v2 |    .464437   .2444287     1.90   0.057    -.0146345    .9435085
          v3 |   .8830596   .2636705     3.35   0.001     .3662749    1.399844
       _cons |  -.8840127   .1454878    -6.08   0.000    -1.169164   -.5988618
------------------------------------------------------------------------------

. predict log2 if fid==1
(option pr assumed; Pr(v58))
(345 missing values generated)

. gen double log_crossfit = log1 if fid==2
(345 missing values generated)

. replace log_crossfit = log2 if fid==1
(345 real changes made)

. 
. assert reldif(log_crossfit , yb1)<10e-6

. 
. 
. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
.                                                  
. use `testdata', clear

. 
. pystacked $model, type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1532334
  lassocv        |      0.0000000
  gradboost      |      0.8467666

. 
. predict double yhat, pr

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .02161697 |
  2. | .01309867 |
  3. | .00747753 |
  4. | .96338006 |
  5. | .98903049 |
     |-----------|
  6. | .01358793 |
  7. | .10357896 |
  8. | .98448453 |
  9. | .07360937 |
     +-----------+

. 
. predict double t, basexb

. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. *******************************************************************************
. *** only one predictor                                                                                                          ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. pystacked v58 v57, type(class) m(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict double xhat1

. 
. logit v58 v57

Iteration 0:   log likelihood = -461.39142  
Iteration 1:   log likelihood = -438.05678  
Iteration 2:   log likelihood = -437.95577  
Iteration 3:   log likelihood = -437.95561  
Iteration 4:   log likelihood = -437.95561  

Logistic regression                                     Number of obs =    690
                                                        LR chi2(1)    =  46.87
                                                        Prob > chi2   = 0.0000
Log likelihood = -437.95561                             Pseudo R2     = 0.0508

------------------------------------------------------------------------------
         v58 | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
         v57 |   .0013024   .0002272     5.73   0.000     .0008571    .0017477
       _cons |  -.7951655   .0972236    -8.18   0.000    -.9857203   -.6046107
------------------------------------------------------------------------------

. predict double xhat2 
(option pr assumed; Pr(v58))

. 
. assert reldif(xhat1,xhat2)<0.0001

. 
. *******************************************************************************
. *** predicted values/classes                                                                                            ***
. *******************************************************************************
. 
. cap drop yhat*

. 
. pystacked $model, type(class) methods(logit)
Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      1.0000000

. predict yhat , class

. predict yhat2  

. predict yhat3 , pr

. assert yhat>0 if yhat3>0.5

. assert yhat<1 if yhat3<0.5

. assert yhat2>0 if yhat3>0.5

. assert yhat2<1 if yhat3<0.5

. 
. *******************************************************************************
. *** try voting                                                                                                                          ***
. *******************************************************************************
. 
. use `testdata', clear

.                         
. pystacked $model, type(class) pyseed(123) ///
>                                                         methods(lassocv rf logit) /// 
>                                                         njobs(4) pipe1(poly2) ///
>                                                         voting voteweights(0.1 .4) ///
>                                                         votetype(soft)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      0.1000000
  rf             |      0.4000000
  logit          |      0.5000000

. mat W = e(weights)

. assert reldif(0.1,el(W,1,1))<0.0001

. assert reldif(0.4,el(W,2,1))<0.0001

. assert reldif(0.5,el(W,3,1))<0.0001

.  
. 
. *******************************************************************************
. *** try other estimators                                                                                                        ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. local m1 logit lassocv gradboost nnet

. local m2 logit lassocv rf nnet

. local m3 logit ridgecv gradboost nnet

. local m4 logit elasticcv gradboost nnet

. local m5 logit elasticcv gradboost svm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" {
  2.         di "`m'"
  3.         pystacked $model, type(class) pyseed(123) ///
>                                                         methods(`m') /// 
>                                                         njobs(4)
  4. }
logit lassocv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0807563
  lassocv        |      0.0000000
  gradboost      |      0.6112265
  nnet           |      0.3080172
logit lassocv rf nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0602403
  lassocv        |      0.0000000
  rf             |      0.4216790
  nnet           |      0.5180808
logit ridgecv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  ridgecv        |      0.0340931
  gradboost      |      0.4721140
  nnet           |      0.4937929
logit elasticcv gradboost nnet

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.0000000
  elasticcv      |      0.0000000
  gradboost      |      0.5803025
  nnet           |      0.4196975
logit elasticcv gradboost svm

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1574005
  elasticcv      |      0.0000000
  gradboost      |      0.4810864
  svm            |      0.3615132


Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.2031101
  lassocv        |      0.0000000
  gradboost      |      0.7968899

. 
. 
. *******************************************************************************
. *** check table option                                                                                                          ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.1419184
  rf             |      0.3417368
  gradboost      |      0.5163447

. pystacked, table

Confusion matrix: In-Sample, CV, Holdout
-----------------------------------------------------------------------------
  Method         | Weight      In-Sample             CV             Holdout
                 |             0       1         0       1         0       1
-----------------+-----------------------------------------------------------
  STACKING     0 |    .       417      13       397      35         .       .
  STACKING     1 |    .         4     256        24     234         .       .
  logit        0 | 0.142      399      39       389      49         .       .
  logit        1 | 0.142       22     230        32     220         .       .
  rf           0 | 0.342      421       1       393      36         .       .
  rf           1 | 0.342        0     268        28     233         .       .
  gradboost    0 | 0.516      416      13       398      34         .       .
  gradboost    1 | 0.516        5     256        23     235         .       .

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.4227930
  rf             |      0.1819019
  gradboost      |      0.3953051

. // default holdout - all available obs
. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample, CV, Holdout
-----------------------------------------------------------------------------
  Method         | Weight      In-Sample             CV             Holdout
                 |             0       1         0       1         0       1
-----------------+-----------------------------------------------------------
  STACKING     0 |    .       201       4       192      15       204      19
  STACKING     1 |    .         2     118        11     107        14     128
  logit        0 | 0.423      198       8       183      16       200      20
  logit        1 | 0.423        5     114        20     106        18     127
  rf           0 | 0.182      203       1       190      21       206      22
  rf           1 | 0.182        0     121        13     101        12     125
  gradboost    0 | 0.395      203       4       196      24       203      24
  gradboost    1 | 0.395        0     118         7      98        15     123

. // specified holdout sample
. pystacked, table holdout(h1)
Number of holdout observations:  175

Confusion matrix: In-Sample, CV, Holdout
-----------------------------------------------------------------------------
  Method         | Weight      In-Sample             CV             Holdout
                 |             0       1         0       1         0       1
-----------------+-----------------------------------------------------------
  STACKING     0 |    .       201       4       192      15        96      11
  STACKING     1 |    .         2     118        11     107         5      63
  logit        0 | 0.423      198       8       183      16        93      11
  logit        1 | 0.423        5     114        20     106         8      63
  rf           0 | 0.182      203       1       190      21        96      13
  rf           1 | 0.182        0     121        13     101         5      61
  gradboost    0 | 0.395      203       4       196      24        96      13
  gradboost    1 | 0.395        0     118         7      98         5      61

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample, CV, Holdout
-----------------------------------------------------------------------------
  Method         | Weight      In-Sample             CV             Holdout
                 |             0       1         0       1         0       1
-----------------+-----------------------------------------------------------
  STACKING     0 |    .       201       6       187      16       200      17
  STACKING     1 |    .         2     116        16     106        18     130
  logit        0 | 0.555      198       8       184      15       200      20
  logit        1 | 0.555        5     114        19     107        18     127
  rf           0 | 0.000      203       1       189      23       206      22
  rf           1 | 0.000        0     121        14      99        12     125
  gradboost    0 | 0.445      203       4       192      24       203      24
  gradboost    1 | 0.445        0     118        11      98        15     123

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.5390052
  rf             |      0.1529283
  gradboost      |      0.3080665

. pystacked, table holdout
Number of holdout observations:  365

Confusion matrix: In-Sample, CV, Holdout
-----------------------------------------------------------------------------
  Method         | Weight      In-Sample             CV             Holdout
                 |             0       1         0       1         0       1
-----------------+-----------------------------------------------------------
  STACKING     0 |    .       201       5       190      20       200      18
  STACKING     1 |    .         2     117        13     102        18     129
  logit        0 | 0.539      196       7       188      22       200      21
  logit        1 | 0.539        7     115        15     100        18     126
  rf           0 | 0.153      203       1       187      21       206      22
  rf           1 | 0.153        0     121        16     101        12     125
  gradboost    0 | 0.308      203       4       193      24       203      24
  gradboost    1 | 0.308        0     118        10      98        15     123

. 
. 
. *******************************************************************************
. *** check graph option                                                                                                          ***
. *******************************************************************************
. 
. use `testdata', clear

. 
. // holdout sample 1
. cap drop h1

. gen h1 = !train2

. 
. // full sample
. pystacked $model, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.2222832
  rf             |      0.1008356
  gradboost      |      0.6768812

. pystacked, graph

. 
. // with holdout sample
. pystacked $model if train, type(class) pyseed(123) methods(logit rf gradboost)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.4649098
  rf             |      0.3468785
  gradboost      |      0.1882117

. // default holdout - all available obs
. pystacked, graph holdout
Number of holdout observations:  365

. // specified holdout sample
. pystacked, graph holdout(h1)
Number of holdout observations:  175

. // histogram option
. pystacked, graph hist holdout
Number of holdout observations:  365

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
Number of holdout observations:  365

. // graphing options - learner graphs
. pystacked, lgraph(percent) hist holdout
Number of holdout observations:  365

. 
. // as pystacked option
. pystacked $model if train, type(class) pyseed(123) ///
>         methods(logit rf gradboost) graph holdout
Number of holdout observations:  365

. 
. // syntax 2
. pystacked $model || method(logit) || method(rf) || method(gradboost) || if train, ///
>         type(class) pyseed(123)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  logit          |      0.4265024
  rf             |      0.0974954
  gradboost      |      0.4760021

. pystacked, graph holdout
Number of holdout observations:  365

. 
. 
end of do-file

. do "cs_pystacked_options.do"

.  
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.6.1
*! last edited: 5mar2023
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.3'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                                        ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(True) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; max_lea
> f_nodes = None; min_impurity_decrease = 0.1; bootstrap = True; oob_score = False; n_jobs = 3; random_state = RandomState(MT19937); warm_start = False; ccp_alpha 
> = 0; max_samples = 10; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = friedman_mse; subsample = 0.8; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_f
> raction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = sqrt; max_leaf_nodes = 4; warm_s
> tart = False; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt  bfolds(4)  

Base learner: elasticcv
Cs = 9; fit_intercept = False; penalty = elasticnet; solver = saga; tol = 0.001; max_iter = 90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = R
> andomState(MT19937); l1_ratios = (0, 0.1, 1); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt bfolds(4) 

Base learner: lassocv
Cs = 9; fit_intercept = False; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = RandomSta
> te(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt bfolds(4)     

Base learner: ridgecv
Cs = 9; fit_intercept = False; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90; n_jobs = 2; refit = True; intercept_scaling = 1.1; random_state = Rand
> omState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = auto; learning_rate = adaptive; learning_rate_init = 0.01; power_t 
> = 0.4; max_iter = 100; shuffle = False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; momentum = 0.8; nesterovs_momentu
> m = True; early_stopping = False; validation_fraction = 0.15; beta_1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = True; tol = 0.01; cache_size = 150; max_iter = 10; decision_functi
> on_shape = ovr; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                                            ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; intercept_scaling = 1.1; dual = False; random_state = RandomState(
> MT19937); max_iter = 900; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter = 10; shrinking = False; cache_size = 200; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = auto; learning_rate = adaptive; learning_rate_init = 0.01; power_t 
> = 0.5; max_iter = 100; shuffle = False; random_state = RandomState(MT19937); tol = 0.0001; verbose = False; warm_start = False; momentum = 0.8; nesterovs_momentu
> m = True; early_stopping = False; validation_fraction = 0.15; beta_1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; max_fun = 14000; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         positive ///
>                         ) showopt bfolds(3) 

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter = 500; tol = 0.001; n_jobs = None; positive = True; selection =
>  cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         positive ///
>                         ) showopt  bfolds(3)    

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_iter = 500; tol = 0.001; n_jobs = None; positive = True; selection 
> = cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = friedman_mse; min_samples_split = 5; min_samples_leaf = 0.1; min_weight
> _fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_no
> des = 4; warm_start = True; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_features = sqrt; m
> ax_leaf_nodes = 4; min_impurity_decrease = 0.1; bootstrap = True; oob_score = False; n_jobs = None; random_state = RandomState(MT19937); warm_start = True; ccp_a
> lpha = 0; max_samples = None; 

Single base learner: no stacking done.

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

.  
. 
end of do-file

. do "cs_pystacked_reg.do"

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.6.1
*! last edited: 5mar2023
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.1.3'

. 
. global xvars crim-lstat

. 
. *******************************************************************************
. *** check that it works without default methods                                                         ***
. *******************************************************************************
. 
. clear all

. use https://statalasso.github.io/dta/cal_housing.dta, clear

. set seed 42

. pystacked medh longi-medi 

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  gradboost      |      1.0000000

. 
. *******************************************************************************
. *** check against SJ paper                                                                                                      ***
. *******************************************************************************
. 
. clear all

. use https://statalasso.github.io/dta/cal_housing.dta, clear

. set seed 42

. gen train=runiform()

. replace train=train<.75
(20,640 real changes made)

. replace medh = medh/10e3 
variable medhousevalue was long now double
(20,640 real changes made)

. label var medh 

. set seed 42

. pystacked medh longi-medi if train,                        ///
>     type(regress)                                          ///
>     methods(ols lassocv lassocv rf gradboost)              ///
>     pipe3(poly2) cmdopt5(learning_rate(0.01)               ///
>     n_estimators(1000))

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassocv        |      0.0000000
  lassocv        |      0.0000000
  rf             |      0.8382714
  gradboost      |      0.1617286

. 
. mat W = e(weights)

. assert reldif(0,el(W,1,1))<0.0001

. assert reldif(0,el(W,2,1))<0.0001

. assert reldif(0,el(W,3,1))<0.0001

. assert reldif(0.8382714,el(W,4,1))<0.0001

. assert reldif(0.1617286,el(W,5,1))<0.0001

. 
. 
. *******************************************************************************
. *** foldvar                                                                                                                                     ***
. *******************************************************************************
. 
. insheet using "/Users/kahrens/Dropbox (PP)/ddml/Data/housing.csv", ///
>         clear comma
(14 vars, 506 obs)

. 
. gen fid = 1 + (_n>250)

.         
. pystacked medv $xvars, method(ols rf) foldvar(fid)

Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  rf             |      1.0000000

. predict yb , basexb cvalid

. 
. reg medv $xvars if _n<=250

      Source |       SS           df       MS      Number of obs   =       250
-------------+----------------------------------   F(13, 236)      =    107.69
       Model |  14969.2255        13  1151.47888   Prob > F        =    0.0000
    Residual |  2523.45072       236  10.6925878   R-squared       =    0.8557
-------------+----------------------------------   Adj R-squared   =    0.8478
       Total |  17492.6762       249  70.2517116   Root MSE        =      3.27

------------------------------------------------------------------------------
        medv | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
        crim |   1.208708   .5165797     2.34   0.020     .1910112    2.226404
          zn |   .0246793   .0139997     1.76   0.079     -.002901    .0522596
       indus |   .0101453    .051355     0.20   0.844    -.0910274    .1113181
        chas |   .4227349   .8157238     0.52   0.605    -1.184296    2.029765
         nox |  -8.480356   4.493227    -1.89   0.060    -17.33231    .3716021
          rm |   8.865556   .4935031    17.96   0.000     7.893322     9.83779
         age |   -.048789   .0117209    -4.16   0.000      -.07188    -.025698
         dis |  -1.123173   .2121414    -5.29   0.000    -1.541106   -.7052403
         rad |   .2089508   .1511725     1.38   0.168    -.0888692    .5067707
         tax |  -.0160083   .0039309    -4.07   0.000    -.0237525   -.0082641
     ptratio |  -.6580104   .1244101    -5.29   0.000    -.9031065   -.4129142
           b |   .0178036   .0052194     3.41   0.001      .007521    .0280863
       lstat |  -.1155318    .057027    -2.03   0.044    -.2278789   -.0031847
       _cons |   -9.94033   5.878804    -1.69   0.092    -21.52197    1.641306
------------------------------------------------------------------------------

. predict ols1 if _n>250
(option xb assumed; fitted values)
(250 missing values generated)

. reg medv $xvars if _n>250

      Source |       SS           df       MS      Number of obs   =       256
-------------+----------------------------------   F(13, 242)      =     52.56
       Model |  17507.9606        13   1346.7662   Prob > F        =    0.0000
    Residual |  6200.28792       242  25.6210244   R-squared       =    0.7385
-------------+----------------------------------   Adj R-squared   =    0.7244
       Total |  23708.2486       255  92.9735238   Root MSE        =    5.0617

------------------------------------------------------------------------------
        medv | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
        crim |  -.1115731   .0360786    -3.09   0.002    -.1826413    -.040505
          zn |   .0467109   .0226302     2.06   0.040     .0021336    .0912883
       indus |  -.1248697   .1586528    -0.79   0.432    -.4373864     .187647
        chas |   6.203216   1.432213     4.33   0.000      3.38202    9.024411
         nox |  -25.37038    6.91223    -3.67   0.000    -38.98619   -11.75456
          rm |   .8986557   .5743273     1.56   0.119     -.232663    2.029974
         age |    .029812   .0256754     1.16   0.247    -.0207637    .0803878
         dis |  -1.569539     .33795    -4.64   0.000    -2.235238   -.9038402
         rad |   .3418979   .0982913     3.48   0.001     .1482821    .5355137
         tax |  -.0045875   .0070141    -0.65   0.514     -.018404    .0092289
     ptratio |  -1.387848   .2406709    -5.77   0.000    -1.861925   -.9137712
           b |   .0058822   .0031425     1.87   0.062    -.0003079    .0120723
       lstat |  -.7205029   .0727863    -9.90   0.000    -.8638784   -.5771273
       _cons |   66.56659   7.426122     8.96   0.000      51.9385    81.19467
------------------------------------------------------------------------------

. predict ols2 if _n<=250
(option xb assumed; fitted values)
(256 missing values generated)

. gen ols_crossfit = ols1 if _n>250
(250 missing values generated)

. replace ols_crossfit = ols2 if _n<=250
(250 real changes made)

. 
. assert reldif(ols_crossfit , yb1)<10e-6

. 
. 
. *******************************************************************************
. *** pystacked with one predictor                                                                                        ***
. *******************************************************************************
. 
. sysuse auto 
no; dataset in memory has changed since last saved
r(4);

end of do-file
r(4);

end of do-file
r(4);
