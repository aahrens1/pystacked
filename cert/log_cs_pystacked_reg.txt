---------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:\Users\ecomes\Documents\GitHub\pystacked\cert\log_cs_pystacked_reg.txt
  log type:  text
 opened on:  26 Oct 2021, 21:34:31

. 
. clear all

.  
. if "`c(username)'"=="kahrens" {
.         adopath + "/Users/kahrens/MyProjects/pystacked"
. }

. else if "`c(username)'"=="ecomes" {
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
  [1]  (BASE)      "C:\LocalStore\ecomes\Stata16\ado\base/"
  [2]  (SITE)      "C:\LocalStore\ecomes\Stata16\ado\site/"
  [3]              "."
  [4]  (PERSONAL)  "C:\LocalStore\ecomes\Dropbox\ado\personal/"
  [5]  (PLUS)      "c:\ado\plus/"
  [6]  (OLDPLACE)  "c:\ado/"
  [7]              "C:\LocalStore\ecomes\Dropbox\Statadat\underid"
  [8]              "C:\LocalStore\ecomes\Dropbox\StataLasso\iclasso"
  [9]              "C:\Users\ecomes\Documents\GitHub\lassopack\lassopack_v141"
  [10]             "C:\Users\ecomes\Documents\GitHub\pdslasso"
  [11]             "C:\Users\ecomes\Documents\GitHub\ddml"
  [12]             "C:\Users\ecomes\Documents\GitHub\pylearn2"
  [13]             "C:\Users\ecomes\Documents\GitHub\pystacked"
  [14]             "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) repla
> ce
. }

. which pystacked 
C:\Users\ecomes\Documents\GitHub\pystacked\pystacked.ado
*! pystacked v0.1 (first release)
*! last edited: 26oct2021
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'0.24.2'

. 
. global xvars lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** voting                                                                           
>                                                            ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .1)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.5000000
  lassoic        |      0.1000000
  rf             |      0.4000000

. 
. // should cause error
. cap pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) /// 
>                                                  voting voteweights(.5 .9)      

.                                                  
. *******************************************************************************
. *** check pipeline                                                                   
>                                                    ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. 
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) 
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1414704
  lassoic        |      0.7752922
  rf             |      0.0832373

. predict a, transf




.                          
. pystacked lpsa c.($xvars)##c.($xvars), ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic )               
>                             
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1540086
  lassoic        |      0.8459914

. predict b, transf



. list lpsa a* b*

     +------------------------------------------------------------------------+
     |      lpsa   age         a1         a2         a3         b1         b2 |
     |------------------------------------------------------------------------|
  1. | -.4307829    50   .2531799    1.19435     .13759   .2531799    1.19435 |
  2. | -.1625189    58   .5338573   1.205396    .069143   .5338573   1.205396 |
  3. | -.1625189    74   .2774684   1.251625   .5021526   .2774684   1.251625 |
  4. | -.1625189    58   .4093789   1.101081   .1248006   .4093789   1.101081 |
  5. |  .3715636    62   1.388298   2.006096   .6309908   1.388298   2.006096 |
     |------------------------------------------------------------------------|
  6. |  .7654678    50   .6148925   1.149503   .4314515   .6148925   1.149503 |
  7. |  .7654678    64   1.843947   2.014224   1.001568   1.843947   2.014224 |
  8. |  .8544153    58   1.820537   2.018032   1.204382   1.820537   2.018032 |
  9. |  1.047319    47   1.383648   1.377017   .8778588   1.383648   1.377017 |
 10. |  1.047319    63   .8287085   1.710201   1.310555   .8287085   1.710201 |
     |------------------------------------------------------------------------|
 11. |  1.266948    65   1.328171   1.849305   1.394067   1.328171   1.849305 |
 12. |  1.266948    63   1.140312   1.148796   1.119272   1.140312   1.148796 |
 13. |  1.266948    63   1.584554   2.300465   1.665706   1.584554   2.300465 |
 14. |  1.348073    67   1.723184   2.231895     1.5656   1.723184   2.231895 |
 15. |  1.398717    57   1.603024    2.27736    1.76954   1.603024    2.27736 |
     |------------------------------------------------------------------------|
 16. |  1.446919    66   1.482576   2.221097   1.633146   1.482576   2.221097 |
 17. |  1.470176    70   1.292764   1.597425   1.648572   1.292764   1.597425 |
 18. |  1.492904    66   1.922884   2.752154   1.942684   1.922884   2.752154 |
 19. |  1.558145    41   1.227521   1.375761   1.185681   1.227521   1.375761 |
 20. |  1.599388    70   1.785388   1.894892   1.774653   1.785388   1.894892 |
     |------------------------------------------------------------------------|
 21. |  1.638997    59   1.690516   2.174275   1.580182   1.690516   2.174275 |
 22. |  1.658228    60   3.007411   2.671294    2.15157   3.007411   2.671294 |
 23. |  1.695616    59   .9841912   1.421073   1.390526   .9841912   1.421073 |
 24. |  1.713798    63   2.333647   2.531999   2.166787   2.333647   2.531999 |
 25. |  1.731655    69   1.696714   1.928332   1.807534   1.696714   1.928332 |
     |------------------------------------------------------------------------|
 26. |  1.766442    68   2.027972   2.202135   1.801851   2.027972   2.202135 |
 27. |  1.800058    65   1.720829   2.077445   2.142257   1.720829   2.077445 |
 28. |  1.816452    67    1.65189   1.733074   1.947935    1.65189   1.733074 |
 29. |  1.848455    67   2.463503   2.089611   2.024031   2.463503   2.089611 |
 30. |  1.894617    65   1.874244   2.709655   2.078271   1.874244   2.709655 |
     |------------------------------------------------------------------------|
 31. |  1.924249    65   2.214339    2.03207   1.987578   2.214339    2.03207 |
 32. |  2.008214    65   1.762027   1.887593   1.936263   1.762027   1.887593 |
 33. |  2.008214    71   1.936752   2.096905   2.061916   1.936752   2.096905 |
 34. |  2.021548    54   .9801115   1.625275   1.814286   .9801115   1.625275 |
 35. |  2.047693    63   .7396169   1.598844   1.811493   .7396169   1.598844 |
     |------------------------------------------------------------------------|
 36. |  2.085672    64   2.349068   2.572035   2.315722   2.349068   2.572035 |
 37. |  2.157559    73   2.323647   2.525409    2.33831   2.323647   2.525409 |
 38. |  2.191653    64   1.390078   1.557253   1.914502   1.390078   1.557253 |
 39. |  2.213754    68   3.187775   3.563096   2.698245   3.187775   3.563096 |
 40. |  2.277267    56   2.618418   1.940984   2.038516   2.618418   1.940984 |
     |------------------------------------------------------------------------|
 41. |  2.297573    60    2.40577   2.038509   2.079149    2.40577   2.038509 |
 42. |  2.307573    68   1.672259   2.469141   2.349403   1.672259   2.469141 |
 43. |  2.327278    62   2.159884   2.083466   2.303073   2.159884   2.083466 |
 44. |  2.374906    61   2.602152    2.69184   2.595668   2.602152    2.69184 |
 45. |  2.521721    66   2.485967   2.387562   2.464077   2.485967   2.387562 |
     |------------------------------------------------------------------------|
 46. |  2.553344    61   2.865782   2.458958   2.546973   2.865782   2.458958 |
 47. |  2.568788    79   2.578777   3.728069   2.883233   2.578777   3.728069 |
 48. |  2.568788    68    2.73771    2.47746   2.642203    2.73771    2.47746 |
 49. |  2.591516    43   2.811579   2.462658   2.368951   2.811579   2.462658 |
 50. |  2.591516    70   1.827751   2.258163    2.35556   1.827751   2.258163 |
     |------------------------------------------------------------------------|
 51. |  2.656757    68   2.698367   2.431077   2.619197   2.698367   2.431077 |
 52. |  2.677591    64   2.955599   2.682204   2.720211   2.955599   2.682204 |
 53. |   2.68444    64   2.330682   2.045715   2.408432   2.330682   2.045715 |
 54. |  2.691243    68   2.802072   2.929722   2.704366   2.802072   2.929722 |
 55. |  2.704711    59   2.795548    3.15413   3.037796   2.795548    3.15413 |
     |------------------------------------------------------------------------|
 56. |     2.718    66    2.71479   2.613106   2.595958    2.71479   2.613106 |
 57. |  2.788093    47   2.567233   1.963605   2.570182   2.567233   1.963605 |
 58. |  2.794228    49   2.200077   1.996474   2.534795   2.200077   1.996474 |
 59. |  2.806386    70   2.370852   2.259464   2.640188   2.370852   2.259464 |
 60. |   2.81241    61   3.403167   2.365178   2.780008   3.403167   2.365178 |
     |------------------------------------------------------------------------|
 61. |  2.841998    73   2.796116   2.258619   2.652102   2.796116   2.258619 |
 62. |  2.853592    63   3.128426   3.067439   2.894105   3.128426   3.067439 |
 63. |  2.853592    72   2.911506   3.135225    3.06972   2.911506   3.135225 |
 64. |  2.882004    66   2.819702   3.160516   2.871333   2.819702   3.160516 |
 65. |  2.882004    64   2.482604   2.649055   2.549042   2.482604   2.649055 |
     |------------------------------------------------------------------------|
 66. |   2.88759    61   2.604916   2.532961   2.770929   2.604916   2.532961 |
 67. |   2.92047    68    2.95794    2.79465   2.897167    2.95794    2.79465 |
 68. |  2.962692    72   2.565041   2.934791   2.908983   2.565041   2.934791 |
 69. |  2.962692    69   2.914459    1.82403   2.541458   2.914459    1.82403 |
 70. |  2.972975    72   2.949435   2.765781   2.841401   2.949435   2.765781 |
     |------------------------------------------------------------------------|
 71. |  3.013081    60    3.21078   2.948282   3.012795    3.21078   2.948282 |
 72. |  3.037354    77   3.096022   2.220091    2.78612   3.096022   2.220091 |
 73. |  3.056357    69    2.96146     2.6809   2.913517    2.96146     2.6809 |
 74. |  3.075006    60   3.065017   2.934107   3.044554   3.065017   2.934107 |
 75. |  3.275256    69    3.72425   3.659978   3.573852    3.72425   3.659978 |
     |------------------------------------------------------------------------|
 76. |  3.337547    68   4.152031   3.521276   3.762278   4.152031   3.521276 |
 77. |  3.392829    72   3.723232   2.994266   3.215779   3.723232   2.994266 |
 78. |  3.435599    78   3.524962   3.194877   3.332311   3.524962   3.194877 |
 79. |  3.457893    69    3.06631    3.37067   3.435096    3.06631    3.37067 |
 80. |  3.513037    63   2.962056   3.104248   3.538206   2.962056   3.104248 |
     |------------------------------------------------------------------------|
 81. |  3.516013    66   2.140939   2.254506    2.89927   2.140939   2.254506 |
 82. |  3.530763    57   3.176303    2.85934   3.187349   3.176303    2.85934 |
 83. |  3.565298    77   3.967295    3.46458   3.463933   3.967295    3.46458 |
 84. |   3.57094    65   3.349466    3.22075   3.415458   3.349466    3.22075 |
 85. |  3.587677    60   2.728997   2.531612    3.24823   2.728997   2.531612 |
     |------------------------------------------------------------------------|
 86. |  3.630985    64   3.963735   3.703329    3.78159   3.963735   3.703329 |
 87. |  3.680091    58   2.822963   2.665586   3.235465   2.822963   2.665586 |
 88. |  3.712352    62     3.3019   2.793578    3.19828     3.3019   2.793578 |
 89. |  3.984344    65   4.148139   3.876298   3.960577   4.148139   3.876298 |
 90. |  3.993603    76   3.821048   2.821789   3.694238   3.821048   2.821789 |
     |------------------------------------------------------------------------|
 91. |  4.029806    68   4.057494    3.32774   3.789711   4.057494    3.32774 |
 92. |  4.129551    61   4.010955   3.343119   3.747733   4.010955   3.343119 |
 93. |  4.385147    68   3.951797   3.578171   4.167612   3.951797   3.578171 |
 94. |  4.684443    44   4.842533   4.124513   4.599427   4.842533   4.124513 |
 95. |  5.143125    52   4.970314    3.44301     4.5115   4.970314    3.44301 |
     |------------------------------------------------------------------------|
 96. |  5.477509    68   4.995613   3.568807   4.628985   4.995613   3.568807 |
 97. |  5.582932    68   4.154709   3.963506   4.901679   4.154709   3.963506 |
     +------------------------------------------------------------------------+

. 
. assert a1==b1

. assert a2==b2

. 
. *******************************************************************************
. *** try various combinations of estimators                                           
>                            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. local m1 ols lassocv gradboost nnet

. local m2 ols lassocv rf nnet

. local m3 ols lassoic gradboost nnet

. local m4 ols ridgecv gradboost nnet

. local m5 ols elasticcv gradboost nnet

. local m6 ols elasticcv gradboost svm

. local m7 ols elasticcv gradboost linsvm

. 
. foreach m in "`m1'" "`m2'" "`m3'" "`m4'" "`m5'" "`m6'" "`m7'" {
  2.         di "`m'"
  3.         pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(`m') /// 
>                                                  njobs(4) ///
>                                                  pipe2(poly2) pipe1(poly2)
  4. }
ols lassocv gradboost nnet
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0739142
  lassocv        |      0.8518984
  gradboost      |      0.0741874
  nnet           |      0.0000000
ols lassocv rf nnet
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0805984
  lassocv        |      0.9194016
  rf             |      0.0000000
  nnet           |      0.0000000
ols lassoic gradboost nnet
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0890671
  lassoic        |      0.5065911
  gradboost      |      0.4043418
  nnet           |      0.0000000
ols ridgecv gradboost nnet
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1125415
  ridgecv        |      0.0000000
  gradboost      |      0.8874585
  nnet           |      0.0000000
ols elasticcv gradboost nnet
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0528410
  elasticcv      |      0.9471590
  gradboost      |      0.0000000
  nnet           |      0.0000000
ols elasticcv gradboost svm
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0528410
  elasticcv      |      0.9471590
  gradboost      |      0.0000000
  svm            |      0.0000000
ols elasticcv gradboost linsvm
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0528410
  elasticcv      |      0.9471590
  gradboost      |      0.0000000
  linsvm         |      0.0000000

. 
. *******************************************************************************
. *** check that predicted value = weighted avg of transform variables            ***
. *******************************************************************************
. 
. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8381682
  lassoic        |      0.1618318
  gradboost      |      0.0000000

.                                                  
. predict double yhat, xb

. list yhat if _n < 10

     +-----------+
     |      yhat |
     |-----------|
  1. | .87184343 |
  2. | .82415214 |
  3. | .55245898 |
  4. | .68730332 |
  5. | 1.7783521 |
     |-----------|
  6. | .88285781 |
  7. | 1.9212648 |
  8. |  2.117333 |
  9. | 1.2686159 |
     +-----------+

. 
. predict double t, transform  




. 
. mat W = e(weights)

. gen myhat = t1*el(W,1,1)+t2*el(W,2,1)+t3*el(W,3,1)

. 
. assert reldif(yhat,myhat)<0.0001

. 
. 
. *******************************************************************************
. *** check for error message when data in memory changed                              
>            ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. pystacked lpsa lcavol lweight age lbph svi lcp gleason pgg45, ///
>                                                  type(regress) pyseed(243) 
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.8381682
  lassoic        |      0.1618318
  gradboost      |      0.0000000

.                                                  
. replace lcavol = 2 * lcavol
(97 real changes made)

. 
. cap predict double yhat, xb

. assert _rc != 0

. 
. *******************************************************************************
. *** check table option                                                               
>                                            ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1414704
  lassoic        |      0.7752922
  rf             |      0.0832373

. pystacked, table
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1414704
  lassoic        |      0.7752922
  rf             |      0.0832373

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.637             .
  ols            | 0.141       0.637             .
  lassoic        | 0.775       0.501             .
  rf             | 0.083       0.728             .

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

. // default holdout - all available obs
. pystacked, table holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.523         0.649
  ols            | 0.000       0.523         0.649
  lassoic        | 0.832       0.317         5.612
  rf             | 0.168       0.582         0.644

. // specified holdout sample
. pystacked, table holdout(h1)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   37

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.523         0.662
  ols            | 0.000       0.523         0.662
  lassoic        | 0.832       0.317         5.957
  rf             | 0.168       0.582         0.659

. // holdout sample overlaps with estimation sample
. cap noi pystacked, table holdout(h2)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785
error - holdout and estimation samples overlap

. assert _rc != 0

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  table holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

MSPE: In-Sample and Out-of-Sample
-----------------------------------------------------
  Method         | Weight   In-Sample   Out-of-Sample
-----------------+-----------------------------------
  STACKING       |    .        0.523         0.649
  ols            | 0.000       0.523         0.649
  lassoic        | 0.832       0.317         5.612
  rf             | 0.168       0.582         0.644

. 
. *******************************************************************************
. *** check graph option                                                               
>                                            ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data, 
>  tab clear
(11 vars, 97 obs)

. 
. set seed 124345

. 
. // holdout sample 1
. cap drop h1

. gen h1 = _n>60

. // holdout sample 2
. cap drop h2

. gen h2 = _n>40

. 
. // postestimation syntax
. 
. // full sample
. pystacked lpsa $xvars, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1414704
  lassoic        |      0.7752922
  rf             |      0.0832373

. // in-sample predictions
. pystacked, graph
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.1414704
  lassoic        |      0.7752922
  rf             |      0.0832373

. 
. // with holdout sample
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

. // in-sample predictions
. pystacked, graph
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

. // default holdout - all available obs
. pystacked, graph holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

. // specified holdout sample
. pystacked, graph holdout(h1)
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   37

. // graphing options - combined graph
. pystacked, graph(subtitle("subtitle goes here")) holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

. // graphing options - learner graphs
. pystacked, lgraph(ytitle("ytitle goes here")) holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

. 
. // as pystacked option
. pystacked lpsa $xvars if _n<50, ///
>                                                  type(regress) pyseed(243) ///
>                                                  methods(ols lassoic rf) ///
>                                                  pipe1(poly2) pipe2(poly2) ///
>                                                  graph holdout
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ols            |      0.0000000
  lassoic        |      0.8320215
  rf             |      0.1679785

Number of holdout observations:   48

. 
. 
. log close
      name:  <unnamed>
       log:  C:\Users\ecomes\Documents\GitHub\pystacked\cert\log_cs_pystacked_reg.txt
  log type:  text
 closed on:  26 Oct 2021, 21:35:20
---------------------------------------------------------------------------------------
