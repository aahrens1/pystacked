--------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_options.txt
  log type:  text
 opened on:  17 Feb 2022, 20:33:50

. 
. clear all

.  
. if "`c(username)'"=="kahrens" {
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [1]  (BASE)      "/Applications/Stata 16/ado/base/"
  [2]  (SITE)      "/Applications/Stata 16/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/ddml"
  [8]              "/Users/kahrens/MyProjects/pystacked"
. }

. else if "`c(username)'"=="ecomes" {
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4
*! last edited: 17feb2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.0'

. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options                                                                                                 
>                       ***
. *******************************************************************************
. 
. pystacked $model, method(gradboost) ///
>                         cmdopt1(learning_rate(0.2) loss(squared_error) n_estimators(400) ///
>                         subsample(0.8) criterion(squared_error) ///
>                         min_samples_split(5) min_samples_leaf(0.1) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0; max_depth = 3; min_impurity_decrease = 0; init
>  = None; random_state = RandomState(MT19937); max_features = None; alpha = 0.9; max_leaf_nodes = None; warm_start 
> = False; validation_fraction = 0.1; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(gradboost) ///
>                         cmdopt1(learning_rate(0.2) loss(squared_error) n_estimators(400) ///
>                         subsample(0.8) criterion(squared_error) ///
>                         min_samples_split(5) min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = None; warm_st
> art = False; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(gradboost) ///
>                         cmdopt1(learning_rate(0.2) ///
>                         loss(squared_error) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = None; warm_st
> art = False; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         loss(squared_error) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = None; warm_st
> art = False; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         loss(squared_error) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///
>                         max_leaf_nodes(4) /// ???
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start
>  = False; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         loss(squared_error) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start
>  = True; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = None; l1_ratio = 1; eps = 0.001; n_alphas = 100; fit_intercept = True; normalize = True; max_iter = 1000; t
> ol = 0.0001; cv = 5; n_jobs = None; positive = False; selection = cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(1 2) ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = [1, 2]; l1_ratio = 1; eps = 0.001; n_alphas = 100; fit_intercept = True; normalize = True; max_iter = 1000;
>  tol = 0.0001; cv = 5; n_jobs = None; positive = False; selection = cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         l1_ratio(.5) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         ) showopt showpywarnings
option l1_ratio() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.001; n_alphas = 20; fit_intercept = False; normalize = True; max_i
> ter = 1000; tol = 0.0001; cv = 5; n_jobs = None; positive = False; selection = cyclic; random_state = RandomState(
> MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         non ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.001; n_alphas = 20; fit_intercept = False; normalize = False; max_
> iter = 1000; tol = 0.0001; cv = 5; n_jobs = None; positive = False; selection = cyclic; random_state = RandomState
> (MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         non ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.001; n_alphas = 20; fit_intercept = False; normalize = False; max_
> iter = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = RandomState(MT
> 19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt showpywarnings

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.001; n_alphas = 20; fit_intercept = False; normalize = True; max_i
> ter = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = RandomState(MT1
> 9937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt showpywarnings // why are no warnings shown                   

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.001; n_alphas = 20; fit_intercept = False; normalize = True; max_i
> ter = 500; tol = 0.001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = RandomState(MT1
> 9937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         loss(squared_error) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings
option loss() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings
option learning_rate() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings
option subsample() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings
option alpha() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt showpywarnings
option validation_fraction() not allowed
r(198);

end of do-file

r(198);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

.                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt showpywarnings
command cmdopt1 is unrecognized
r(199);

end of do-file

r(199);

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt showpywarnings

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; min_wei
> ght_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_decrease = 0.1; bootstrap = True; o
> ob_score = False; n_jobs = None; random_state = RandomState(MT19937); warm_start = True; ccp_alpha = 0; max_sample
> s = None; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
end of do-file

. do "/var/folders/hj/47q1qh7d7g12z31w_539my0w0000gs/T//SD97337.000000"

. cap cd "/Users/kahrens/MyProjects/pystacked/cert"

. cap cd "/Users/ecomes/Documents/GitHub/pystacked/cert"

. 
. cap log close
