--------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/kahrens/MyProjects/pystacked/cert/log_cs_pystacked_options.txt
  log type:  text
 opened on:  21 Feb 2022, 11:34:40

. 
. clear all

.  
. if "`c(username)'"=="kahrens" {
.         adopath + "/Users/kahrens/MyProjects/pystacked"
  [1]  (BASE)      "/Applications/Stata 16/ado/base/"
  [2]  (SITE)      "/Applications/Stata 16/ado/site/"
  [3]              "."
  [4]  (PERSONAL)  "/Users/kahrens/Documents/Stata/ado/personal/"
  [5]  (PLUS)      "/Users/kahrens/Library/Application Support/Stata/ado/plus/"
  [6]  (OLDPLACE)  "~/ado/"
  [7]              "/Users/kahrens/MyProjects/pystacked"
. }

. else if "`c(username)'"=="ecomes" {
.         adopath + "/Users/ecomes/Documents/GitHub/pystacked/cert"
. }

. else {
.         net install pystacked, ///
>                 from(https://raw.githubusercontent.com/aahrens1/pystacked/main) replace
. }

. 
. which pystacked 
/Users/kahrens/MyProjects/pystacked/pystacked.ado
*! pystacked v0.4.1
*! last edited: 18feb2022
*! authors: aa/ms

. python: import sklearn

. python: sklearn.__version__
'1.0'

. 
. global model lpsa lcavol lweight age lbph svi lcp gleason pgg45

. 
. *******************************************************************************
. *** check options classification                                                                                  
>       ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. sum lpsa, meanonly

. replace lpsa = lpsa > `r(mean)'
(97 real changes made)

. 
. pystacked $model, method(rf) type(class) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(entropy) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         bootstrap(False) ///
>                         n_jobs(3) ///
>                         max_samples(10) ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = entropy; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; min_weight_fr
> action_leaf = 0.1; max_features = sqrt; max_leaf_nodes = None; min_impurity_decrease = 0.1; bootstrap = False; oob
> _score = False; n_jobs = 3; random_state = RandomState(MT19937); warm_start = False; ccp_alpha = 0; max_samples = 
> 10; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. pystacked $model, method(gradboost) type(class) ///
>                         cmdopt1( ///
>                         loss(exponential) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = exponential; learning_rate = 0.2; n_estimators = 400; criterion = squared_error; subsample = 0.8; min_samples
> _split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; in
> it = None; random_state = RandomState(MT19937); max_features = sqrt; max_leaf_nodes = 4; warm_start = False; valid
> ation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(elasticcv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         l1_ratios(0 0.1 1) ///
>                         ) showopt   

Base learner: elasticcv
Cs = 9; fit_intercept = False; cv = 4; penalty = elasticnet; solver = saga; tol = 0.001; max_iter = 90; n_jobs = 2; 
> refit = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); l1_ratios = (0, 0.1, 1); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  elasticcv      |      1.0000000

. 
. pystacked $model, method(lassocv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt  

Base learner: lassocv
Cs = 9; fit_intercept = False; cv = 4; penalty = l1; solver = saga; tol = 0.001; max_iter = 90; n_jobs = 2; refit = 
> True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) type(class) ///
>                         cmdopt1( ///
>                         c(9) ///
>                         nocons ///
>                         cv(4) ///
>                         tol(0.001) ///
>                         max_iter(90) ///
>                         n_jobs(2) ///
>                         intercept_scaling(1.1) ///
>                         ) showopt       

Base learner: ridgecv
Cs = 9; fit_intercept = False; cv = 4; penalty = l2; solver = newton-cg; tol = 0.001; max_iter = 90; n_jobs = 2; ref
> it = True; intercept_scaling = 1.1; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

. 
. pystacked $model, method(nnet) type(class) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         power_t(0.4) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = auto; learning_rate 
> = adaptive; learning_rate_init = 0.01; power_t = 0.4; max_iter = 100; shuffle = False; random_state = RandomState(
> MT19937); tol = 0.0001; verbose = False; warm_start = False; momentum = 0.8; nesterovs_momentum = True; early_stop
> ping = False; validation_fraction = 0.15; beta_1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; ma
> x_fun = 14000; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(svm) type(class) ///
>                         cmdopt1( ///
>                         c(0.1) ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.01) ///
>                         shrinking(False) ///
>                         tol(1e-2) ///
>                         cache_size(150) ///
>                         max_iter(10) ///
>                         ) showopt 

Base learner: svm
C = 0.1; kernel = poly; degree = 2; gamma = auto; coef0 = 0.01; shrinking = False; probability = True; tol = 0.01; c
> ache_size = 150; max_iter = 10; decision_function_shape = ovr; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

.                         
.                         
.                         
. *******************************************************************************
. *** check options regression                                                                                      
>       ***
. *******************************************************************************
. 
. clear

. insheet using https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data,  tab clear
(11 vars, 97 obs)

. 
. pystacked $model, method(linsvm) ///
>                         cmdopt1( ///
>                         epsilon(0.01) ///
>                         tol(1e-3) ///
>                         c(1.1) ///
>                         loss(squared_epsilon_insensitive) ///
>                         nocons ///
>                         intercept_scaling(1.1) ///
>                         dual(False) ///
>                         max_iter(900) ///
>                         ) showopt       

Base learner: linsvm
epsilon = 0.01; tol = 0.001; C = 1.1; loss = squared_epsilon_insensitive; fit_intercept = False; intercept_scaling =
>  1.1; dual = False; random_state = RandomState(MT19937); max_iter = 900; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  linsvm         |      1.0000000

. 
. pystacked $model, method(svm) ///
>                         cmdopt1( ///
>                         kernel(poly) ///
>                         degree(2) ///
>                         gamma(auto) ///
>                         coef0(0.1) ///
>                         tol(1e-2) ///
>                         c(1.1) ///
>                         epsilon(0.14) ///
>                         shrinking(False) ///
>                         max_iter(10) ///
>                         ) showopt       

Base learner: svm
kernel = poly; degree = 2; gamma = auto; coef0 = 0.1; tol = 0.01; C = 1.1; epsilon = 0.14; max_iter = 10; shrinking 
> = False; cache_size = 200; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  svm            |      1.0000000

. 
. pystacked $model, method(nnet) ///
>                         cmdopt1( ///
>                         hidden_layer_sizes(5 5) ///
>                         activation(logistic) ///
>                         alpha(0.0002) ///
>                         learning_rate(adaptive) ///
>                         learning_rate_init(0.01) ///
>                         max_iter(100) ///
>                         shuffle(False) ///
>                         momentum(0.8) ///
>                         validation_fraction(0.15) ///
>                         beta_1(0.91) ///
>                         beta_2(0.991) ///
>                         epsilon(1e-7) ///
>                         n_iter_no_change(9) ///
>                         max_fun(14000) ///
>                         ) showopt                       

Base learner: nnet
hidden_layer_sizes = (5, 5); activation = logistic; solver = adam; alpha = 0.0002; batch_size = auto; learning_rate 
> = adaptive; learning_rate_init = 0.01; power_t = 0.5; max_iter = 100; shuffle = False; random_state = RandomState(
> MT19937); tol = 0.0001; verbose = False; warm_start = False; momentum = 0.8; nesterovs_momentum = True; early_stop
> ping = False; validation_fraction = 0.15; beta_1 = 0.91; beta_2 = 0.991; epsilon = 1e-07; n_iter_no_change = 9; ma
> x_fun = 14000; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  nnet           |      1.0000000

. 
. pystacked $model, method(lassocv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.1) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt  

Base learner: lassocv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 1; eps = 0.1; n_alphas = 20; fit_intercept = False; max_iter = 500; tol = 0.0
> 01; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  lassocv        |      1.0000000

. 
. pystacked $model, method(ridgecv) ///
>                         cmdopt1( ///
>                         alphas(0.01 0.1 1 2) ///
>                         eps(0.01) ///
>                         n_alphas(20) ///
>                         nocons ///
>                         max_iter(500) ///
>                         tol(0.001) ///
>                         cv(3) ///
>                         positive ///
>                         ) showopt       

Base learner: ridgecv
alphas = [0.01, 0.1, 1, 2]; l1_ratio = 0; eps = 0.01; n_alphas = 20; fit_intercept = False; max_iter = 500; tol = 0.
> 001; cv = 3; n_jobs = None; positive = True; selection = cyclic; random_state = RandomState(MT19937); 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  ridgecv        |      1.0000000

.                         
. pystacked $model, method(gradboost) ///
>                         cmdopt1( ///
>                         loss(squared_error) ///
>                         learning_rate(0.2) ///
>                         n_estimators(400) ///
>                         subsample(0.8) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         alpha(.8) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         validation_fraction(.15) ///
>                         ) showopt  

Base learner: gradboost
loss = squared_error; learning_rate = 0.2; n_estimators = 400; subsample = 0.8; criterion = squared_error; min_sampl
> es_split = 5; min_samples_leaf = 0.1; min_weight_fraction_leaf = 0.1; max_depth = 3; min_impurity_decrease = 0.1; 
> init = None; random_state = RandomState(MT19937); max_features = sqrt; alpha = 0.8; max_leaf_nodes = 4; warm_start
>  = True; validation_fraction = 0.15; n_iter_no_change = None; tol = 0.0001; ccp_alpha = 0; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  gradboost      |      1.0000000

. 
. pystacked $model, method(rf) ///
>                         cmdopt1( ///
>                         n_estimators(400) ///
>                         criterion(squared_error) ///
>                         min_samples_split(5) ///
>                         min_samples_leaf(0.1) ///
>                         min_weight_fraction_leaf(.1) ///
>                         max_depth(3) ///        
>                         min_impurity_decrease(.1) ///
>                         max_features(sqrt) ///
>                         max_leaf_nodes(4) /// 
>                         warm_start ///
>                         ) showopt 

Base learner: rf
n_estimators = 400; criterion = squared_error; max_depth = 3; min_samples_split = 5; min_samples_leaf = 0.1; min_wei
> ght_fraction_leaf = 0.1; max_features = sqrt; max_leaf_nodes = 4; min_impurity_decrease = 0.1; bootstrap = True; o
> ob_score = False; n_jobs = None; random_state = RandomState(MT19937); warm_start = True; ccp_alpha = 0; max_sample
> s = None; 

Single base learner: no stacking done.
Stacking weights:
---------------------------------------
  Method         |      Weight
-----------------+---------------------
  rf             |      1.0000000

. 
. 
. cap log close
